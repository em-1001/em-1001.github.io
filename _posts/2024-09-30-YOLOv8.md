---
title:  "YOLOv8"
excerpt: "YOLOv8 paper"

categories:
  - Computer Vision
tags:
  - AI
  - Computer Vision
  - Paper
last_modified_at: 2024-09-29T08:06:00-05:00
---


# Background
## Cross Entropy
Cross Entropy ëŠ” ì •ë³´ ì´ë¡ ì—ì„œ íŒŒìƒëœ ê°œë…ìœ¼ë¡œ, í™•ë¥  ë¶„í¬ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œì´ë‹¤. ë‘ í™•ë¥  ë¶„í¬ ê°„ì˜ ìœ ì‚¬ì„±ì„ í‰ê°€í•˜ê±°ë‚˜, ë¶„ë¥˜ ë¬¸ì œì—ì„œ ì˜ˆì¸¡ê°’ê³¼ ì‹¤ì œê°’ ê°„ì˜ ì°¨ì´ë¥¼ ê³„ì‚°í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤. 

ë°ì´í„° í™•ë¥  ë¶„í¬ë¥¼ $P(x)$, ëª¨ë¸ì´ ì¶”ì •í•˜ëŠ” í™•ë¥  ë¶„í¬ë¥¼ $Q(x)$ë¼ê³  í•  ë•Œ, ë‘ í™•ë¥  ë¶„í¬ $P$ì™€ $Q$ì˜ ì°¨ì´ë¥¼ ì¸¡ì •í•˜ëŠ” ì§€í‘œì¸ Cross EntropyëŠ” ì•„ë˜ì™€ ê°™ì´ í‘œí˜„ëœë‹¤. 

$$H(p, q) = H(p) + D_{KL}(p \parallel q) = -\sum_{i=0}^{n} p(x_i)\log{(q(x_i))}$$

ì¼ë°˜ì ì¸ Classification ë¬¸ì œì—ì„œ ì£¼ë¡œ cross entropy lossë¥¼ ì‚¬ìš©í•œë‹¤. ì´ë•Œ True distribution $P$ëŠ” one-hot ì¸ì½”ë”©ëœ vector(Ground Truth)ë¥¼ ì‚¬ìš©í•œë‹¤. Prediction distribution $Q$ ëŠ” ëª¨ë¸ì˜ ì˜ˆì¸¡ ê°’ìœ¼ë¡œ softmax layerë¥¼ ê±°ì¹œ í›„ì˜ ê°’ì´ê³ , í´ë˜ìŠ¤ ë³„ í™•ë¥  ê°’ì„ ëª¨ë‘ í•©ì¹˜ë©´ 1ì´ ëœë‹¤. 

ì˜ˆë¥¼ ë“¤ì–´ $P = [0, 1, 0]$,  $Q = [0.2, 0.7, 0.1]$ ì¼ ë•Œ, cross entropy loss ê²°ê³¼ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.

$$
\begin{aligned}
H(P,Q)&=-\sum P(x)log Q(x)\\
&=-(0 \cdot \log{0.2} + 1 \cdot \log{0.7} + 0 \cdot \log{0.1})\\
&=-\log{0.7}
\end{aligned}$$

ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì—ì„œì˜ cross entropyëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ëœë‹¤. 

$$H(y, \hat{y}) = -\frac{1}{N} \sum_{i=1}^N (y_i \log{(\hat{y}_i)} + (1-y_i) \log{(1 - \hat{y}_i)})$$

$y_i$ëŠ” ì‹¤ì œ í´ë˜ìŠ¤ë¥¼ ë‚˜íƒ€ë‚´ëŠ” ê°’(0 ë˜ëŠ” 1)ì´ê³ , $\hat{y}_i$ëŠ” ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì„ ë‚˜íƒ€ë‚¸ë‹¤.   

ìœ„ ì‹ì€ ë‹¤ìŒê³¼ ê°™ì´ ìœ ë„ëœë‹¤.
1. ì •ë³´ ì´ë¡ ì  ê´€ì   
ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì—ì„œ, ì‹¤ì œê°’ $y$ê°€ 1ì´ë¼ë©´ ëª¨ë¸ì€ 1ë¡œ ì˜ˆì¸¡í•´ì•¼ í•˜ë©°, cross entropyëŠ” $-log(\hat{y})$ê°€ ë˜ì–´ì•¼í•œë‹¤.
ë°˜ëŒ€ë¡œ ì‹¤ì œê°’ $y$ê°€ 0ì´ë¼ë©´ ëª¨ë¸ì€ 0ìœ¼ë¡œ ì˜ˆì¸¡í•´ì•¼ í•˜ë©°, cross entropyëŠ” $-log(1 - \hat{y})$ê°€ ëœë‹¤.
2. í‰ê· í™” ë° í•©ì‚°  
ì´ëŸ¬í•œ ê´€ì ì—ì„œ ì „ì²´ ë°ì´í„°ì…‹ì— ëŒ€í•´ ê°ê°ì˜ ê²½ìš°(ì‹¤ì œê°’ì´ 1 ë˜ëŠ” 0ì¸ ê²½ìš°)ì˜ êµì°¨ ì—”íŠ¸ë¡œí”¼ë¥¼ í•©ì‚°í•˜ì—¬ í‰ê· ì„ ì·¨í•œ ê²ƒì´ ìµœì¢…ì ì¸ ì´ì§„ ë¶„ë¥˜ ë¬¸ì œì˜ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ í•¨ìˆ˜ì˜ ì‹ì´ ëœë‹¤.


ìœ„ ì‹ì€ ì‹¤ì œ ë¶„í¬(Ground Truth)ì¸ $y_i$ì™€ ëª¨ë¸ì˜ ì˜ˆì¸¡ì¸ $\hat{y}_i$ì‚¬ì´ì˜ ì •ë³´ëŸ‰ì„ ì¸¡ì •í•˜ê³  ëª¨ë¸ì´ Ground Truthì™€ ì¼ì¹˜í• ìˆ˜ë¡, Cross Entropyì˜ ê°’ì€ ì‘ì•„ì§„ë‹¤.  

## CIoU
### Complete-IoU(CIoU)
DIoU, CIoUë¥¼ ì œì•ˆí•œ ë…¼ë¬¸ì—ì„œ ë§í•˜ëŠ” ì„±ê³µì ì¸ Bounding Box Regressionì„ ìœ„í•œ 3ê°€ì§€ ì¡°ê±´ì€ overlap area, central point
distance, aspect ratioì´ë‹¤. ì´ ì¤‘ overlap area, central pointëŠ” DIoUì—ì„œ ì´ë¯¸ ê³ ë ¤í–ˆê³  ì—¬ê¸°ì— aspect ratioë¥¼ ê³ ë ¤í•œ penalty termì„ ì¶”ê°€í•œ ê²ƒì´ CIoUì´ë‹¤. CIoU penalty termëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤. 

$$\mathcal{R}_{CIoU} = \frac{\rho^2(b, b^{gt})}{c^2} + \alpha v$$

$$v = \frac{4}{Ï€^2}(\arctan{\frac{w^{gt}}{h^{gt}}} - \arctan{\frac{w}{h}})^2$$

$$\alpha = \frac{v}{(1 - IoU) + v}$$

$v$ì˜ ê²½ìš° bboxëŠ” ì§ì‚¬ê°í˜•ì´ê³  $\arctan{\frac{w}{h}} = \theta$ì´ë¯€ë¡œ $\theta$ì˜ ì°¨ì´ë¥¼ í†µí•´ aspect ratioë¥¼ êµ¬í•˜ê²Œ ëœë‹¤. ì´ë•Œ $v$ì— $\frac{2}{Ï€}$ê°€ ê³±í•´ì§€ëŠ” ì´ìœ ëŠ” $\arctan$ í•¨ìˆ˜ì˜ ìµœëŒ€ì¹˜ê°€ $\frac{2}{Ï€}$ ì´ë¯€ë¡œ scaleì„ ì¡°ì •í•´ì£¼ê¸° ìœ„í•´ì„œì´ë‹¤. 

$\alpha$ëŠ” trade-off íŒŒë¼ë¯¸í„°ë¡œ IoUê°€ í° boxì— ëŒ€í•´ ë” í° penaltyë¥¼ ì£¼ê²Œ ëœë‹¤. 

CIoUì— ëŒ€í•´ ìµœì í™”ë¥¼ ìˆ˜í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ê¸°ìš¸ê¸°ë¥¼ ì–»ê²Œ ëœë‹¤. ì´ë•Œ, $w, h$ëŠ” ëª¨ë‘ 0ê³¼ 1ì‚¬ì´ë¡œ ê°’ì´ ì‘ì•„ gradient explosionì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì‹¤ì œ êµ¬í˜„ ì‹œì—ëŠ” $\frac{1}{w^2 + h^2} = 1$ë¡œ ì„¤ì •í•œë‹¤. 

$$\frac{\partial v}{\partial w} = \frac{8}{Ï€^2}(\arctan{\frac{w^{gt}}{h^{gt}}} - \arctan{\frac{w}{h}}) \times \frac{h}{w^2 + h^2}$$ 

$$\frac{\partial v}{\partial h} = -\frac{8}{Ï€^2}(\arctan{\frac{w^{gt}}{h^{gt}}} - \arctan{\frac{w}{h}}) \times \frac{w}{w^2 + h^2}$$ 

## QFL, DFL, GFL
One-stage detectorëŠ” ê¸°ë³¸ì ìœ¼ë¡œ object detectionì„ dense classificationê³¼ localization (i.e., bounding box regression)ì„ í†µí•´ì„œ í•œë‹¤. classificationì˜ ê²½ìš° Focal Lossë¡œ ìµœì í™” ë˜ê³ , box locationì€ Dirac delta distributionìœ¼ë¡œ í•™ìŠµëœë‹¤. QFL, DFLë¥¼ ì œì•ˆí•œ ë…¼ë¬¸ì—ì„œ ë§í•˜ëŠ” ê¸°ì¡´ ë°©ì‹ì˜ ë¬¸ì œëŠ” í¬ê²Œ ë‘ ê°€ì§€ì´ë‹¤. 
1. í•™ìŠµ, ì¶”ë¡  ì‹œ quality estimationê³¼ classificationì˜ ë¹„ì¼ê´€ì„±   
í•™ìŠµì‹œ classification score ì™€ centerness(ë˜ëŠ” iou)score ê°€ ë³„ê°œë¡œ í•™ìŠµë˜ì§€ë§Œ inference ì‹œì—ëŠ” nmsì „ì— ë‘ scoreë¥¼ joiní•´ì„œ ì‚¬ìš©(element wise multiplication)í•œë‹¤. ì´ëŸ¬í•œ ë‘ scoreì˜ ë¹„ì¼ê´€ì„±ì€ ì„±ëŠ¥ì €í•˜ë¡œ ì´ì–´ì§ˆ ìˆ˜ ìˆê³  ë…¼ë¬¸ì—ì„œëŠ” ë‘ scoreë¥¼ train, test ëª¨ë‘ì—ì„œ jointí•´ì£¼ì–´ ë‘˜ ì‚¬ì´ì˜ ìƒê´€ì„±ì„ í¬ê²Œ ê°–ë„ë¡ ìœ ë„í–ˆë‹¤. 
2. Dirac delta distributionì˜ Inflexible  
ê¸°ì¡´ ë°©ì‹ë“¤ì€ positive sample ìœ„ì¹˜ì—ë§Œ box gtë¥¼ í• ë‹¹í•´ regression í•˜ëŠ” ë°©ì‹ì„ ì·¨í•˜ëŠ”ë° ì´ëŠ” dirac delta distributionìœ¼ë¡œ ë³¼ ìˆ˜ ìˆë‹¤. dirac delta distributionëŠ” ë¬¼ì²´ì˜ occlusion, shadow, blurë“±ìœ¼ë¡œ ì¸í•œ ë¬¼ì²´ ê²½ê³„ ë¶ˆë¶„ëª… ë“±ì˜ ë¬¸ì œë¥¼ ì˜ ì»¤ë²„í•˜ì§€ ëª»í•œë‹¤.

### Quality Focal Loss(QFL)
trainingê³¼ test ì‹œì˜ inconsistencyë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ì„œ supervisionì„ ê¸°ì¡´ì˜ one-hot labelì—ì„œ float target $y âˆˆ [0, 1]$ì´ ê°€ëŠ¥í•˜ë„ë¡ softení•˜ì˜€ë‹¤. ì°¸ê³ ë¡œ ì—¬ê¸°ì„œ $y=0$ì€ 0 quality scoreë¥¼ ê°–ëŠ” negative samplesì„, $0 < y â‰¤ 1$ëŠ” target IoU score $y$ë¥¼ ê°–ëŠ” positive samplesì„ ì˜ë¯¸í•˜ê²Œ ëœë‹¤. ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” QFLëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤. 

$$QFL(\sigma) = -\vert y - \sigma \vert ^{\beta}((1-y)\log{(1 - \sigma)} + y \log{(\sigma)})$$

ê¸°ì¡´ì˜ Focal Lossì˜ ê²½ìš° $\{ 1, 0 \}$ì˜ discrete labelsë§Œ ì§€ì›í•˜ì˜€ì§€ë§Œ QFLì—ì„œ ì‚¬ìš©í•˜ëŠ” ìƒˆë¡œìš´ labelì€ decimalsì„ í¬í•¨í•˜ë¯€ë¡œ ìœ„ì™€ ê°™ì€ ì‹ì´ ë‚˜ì™”ê³  ê¸°ì¡´ FLì—ì„œ ë°”ë€ ë¶€ë¶„ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. 

1. ê¸°ì¡´ cross entropy partì¸ $-\log{(p_t)}$ê°€ complete versionì¸ $-((1-y)\log{(1 - \sigma)} + y \log{(\sigma)})$ë¡œ í™•ì¥ë˜ì—ˆë‹¤.   
2. scaling factorì¸ $(1-p_t)^{\gamma}$ê°€ estimation $\sigma$ì™€ continuous labe $y$ ì‚¬ì´ì˜ absolute distanceì¸ $\vert y - \sigma \vert ^{\beta}$ë¡œ ë³€ê²½ë˜ì—ˆë‹¤. ($\vert Â· \vert$ëŠ” non-negativitë¥¼ ë³´ì¥í•œë‹¤.)

### Distribution Focal Loss(DFL)
ê¸°ì¡´ bounding box regressionì˜ ê²½ìš° ì•ì„œ ì–¸ê¸‰í–ˆë“¯ì´ Dirac delta distribution $\delta(x - y)$ë¥¼ ì´ìš©í•´ì„œ regressionë˜ì—ˆë‹¤. 
ì´ëŠ” ì£¼ë¡œ fully connected layersë¥¼ í†µí•´ implementedë˜ë©° ì•„ë˜ì™€ ê°™ë‹¤. 

$$y=\int_{-\infty}^{+\infty} \delta(x - y)x \ dx$$

ë…¼ë¬¸ì—ì„œëŠ” Dirac deltaë‚˜ Gaussian ëŒ€ì‹ ì— General distribution $P(x)$ì„ ì§ì ‘ í•™ìŠµí•˜ëŠ” ê²ƒì„ ì œì•ˆí•œë‹¤. label $y$ì˜ ë²”ìœ„ëŠ” $y_0 â‰¤ y â‰¤ y_n, n \in \mathbb{N}^+$ì— ì†í•˜ê³  estimated valueì¸ $\hat{y}$ë¥¼ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•œë‹¤. ë¬¼ë¡  $\hat{y}$ë„ $y_0 â‰¤ \hat{y} â‰¤ y_n$ë¥¼ ë§Œì¡±í•œë‹¤. 

$$\hat{y}=\int_{-\infty}^{+\infty} P(x)x \ dx = \int_{y_0}^{y_n} P(x)x \ dx$$

ì´ë•Œ í•™ìŠµí•˜ëŠ” labelì˜ ë¶„í¬ê°€ ì—°ì†ì ì´ì§€ ì•Šê³  ì´ì‚°ì ì´ë¯€ë¡œ ìœ„ ì‹ì„ ì•„ë˜ì™€ ê°™ì´ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤. 

$$\hat{y} = \sum_{i=0}^{n} P(y_i)y_i$$

ì´ë•Œ intervals $âˆ†$ì€ ê°„ë‹¨í•˜ê²Œ $âˆ† = 1$ë¡œ í•˜ê³ , $\sum P(y_i) = 1$ì„ ë§Œì¡±í•œë‹¤. 
ìœ„ ì‹ì—ì„œ $y_i$ëŠ” object ì¤‘ì‹¬ìœ¼ë¡œë¶€í„° ê° ë³€ê¹Œì§€ì˜ ê±°ë¦¬ì˜ discreteí•œ ê°’ì´ê³  $P(y_i)$ëŠ” ë„¤íŠ¸ì›Œí¬ê°€ ì¶”ë¡ í•œ í˜„ anchorì—ì„œ boundaryê¹Œì§€ì˜ ê±°ë¦¬ê°€ $y_i$ì¼ í™•ë¥ ì´ë‹¤. ë”°ë¼ì„œ DFLì€ object boundary ê¹Œì§€ì˜ ê±°ë¦¬ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì¶”ë¡ í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ ê° ê±°ë¦¬ì— ëŒ€í•œ í™•ë¥  ê°’ì´ ìˆìœ¼ë©´ ì´ ê°’ë“¤ì˜ ê¸°ëŒ“ê°’ìœ¼ë¡œ ì¶”ë¡ í•˜ëŠ” ê²ƒì´ë‹¤. 

$P(x)$ëŠ” softmax $S(\cdot)$ì„ í†µí•´ ì‰½ê²Œ êµ¬í•´ì§ˆ ìˆ˜ ìˆë‹¤. ë˜í•œ $P(y_i)$ë¥¼ ê°„ë‹¨í•˜ê²Œ $S_i$ë¡œ í‘œí˜„í•œë‹¤. DFLì„ í†µí•œ í•™ìŠµì€ $P(x)$ì˜ í˜•íƒœê°€ targetì¸ $y$ì— ê°€ê¹Œìš´ ê°’ì´ ë†’ì€ probabilitiesë¥¼ ê°–ë„ë¡ ìœ ë„í•œë‹¤. ë”°ë¼ì„œ DFLì€ target $y$ì— ê°€ì¥ ê°€ê¹Œìš´ ë‘ ê°’ $y_i, y_{i+1}$ ($y_i â‰¤ y â‰¤ y_{i+1}$)ì˜ probabilitiesë¥¼ ë†’ì„ìœ¼ë¡œì„œ ë„¤íŠ¸ì›Œí¬ê°€ ë¹ ë¥´ê²Œ label $y$ì— ì§‘ì¤‘í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤. 
DFLì€ QFLì˜ complete cross entropy partë¥¼ ì´ìš©í•˜ì—¬ ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤. 

$$DFL(S_i, S_{i+1}) = -((y_{i+1} - y) \log{(S_i)} + (y - y_i) \log{(S_{i+1})})$$

DFLì˜ global minimum solutionì€ $S_i = \frac{y_{i+1} - y}{y_{i+1} - y_i}, \ S_{i+1} = \frac{y - y_i}{y_{i+1} - y_i}$ê°€ ë˜ê³  ì´ë¥¼ í†µí•´ ê³„ì‚°í•œ estimated regression target $\hat{y}$ëŠ” corresponding labe $y$ì— ë¬´í•œíˆ ê°€ê¹ë‹¤.    
i.e. $\hat{y} = \sum P(y_j)y_j = S_i y_i + S_{i+1} y_{i+1} = \frac{y_{i+1} - y}{y_{i+1} - y_i} y_i + \frac{y - y_i}{y_{i+1} - y_i} y_{i+1} = y$

### Generalized Focal Loss (GFL)
QFLì™€ DFLë¥¼ ì¼ë°˜í™”ëœ í˜•íƒœë¡œ í•©ì¹œê²ƒì´ GFLì´ë‹¤. $y_l, y_r \ (y_l < y_r)$ì— ëŒ€í•œ í™•ë¥ ì€ $p_{y_l}, p_{y_r} \ (p_{y_l}â‰¥0, p_{y_r}â‰¥0, p_{y_l} + p_{y_r} = 1)$ì´ê³ , ìµœì¢… prediction ê°’ì˜ linear combinationì€ $\hat{y} = y_lp_{y_l} + y_rp_{y_r} \ (y_l â‰¤ \hat{y} â‰¤ y_r)$ì´ë‹¤. prediction $\hat{y}$ì— ëŒ€í•œ corresponding continuous labelì¸ $y$ë„ $y_l â‰¤ y â‰¤ y_r$ë¥¼ ë§Œì¡±í•œë‹¤. $\vert y - \hat{y}\vert ^{\beta} \ (\beta â‰¥ 0)$ë¥¼ modulating factorë¡œ ê³„ì‚°í•˜ì—¬ GFLì€ ë‹¤ìŒê³¼ ê°™ì´ êµ¬í•´ì§„ë‹¤. 

$$GFL(p_{y_l}, p_{y_r}) = -\vert y - (y_lp_{y_l} + y_rp_{y_r})\vert ^{\beta} ((y_{r} - y) \log{(p_{y_l})} + (y - y_l) \log{(p_{y_r})})$$

ë…¼ë¬¸ì—ì„œëŠ” QFLì™€ DFLê°€ GFLì˜ special casesë¼ê³  í•œë‹¤. 

**QFL** : Having $y_l = 0, y_r = 1, p_{y_r} = \sigma$ and $p_{y_l} = 1 - \sigma$ in GFL, the form of QFL can be written as:  
$$QFL(\sigma) = GFL(1-\sigma, \sigma) = -\vert y - \sigma\vert ^{\beta}((1-y)\log{(1 - \sigma)} + y \log{(\sigma)})$$

$y_l â‰¤ y_r$ì´ë¯€ë¡œ ë‹¹ì—°íˆ $y_l = 0, y_r = 1$ê°€ ëœë‹¤. $p_{y_r} = \sigma$ì¸ ì´ìœ ëŠ” $\sigma$ê°€ ëª¨ë¸ì˜ ì˜ˆì¸¡ í™•ë¥ ì´ê³ , $y=1$ì¼ ë•Œ $y_r=1$ì´ë¯€ë¡œ $y_r$ì˜ í™•ë¥ ì— ëŒ€í•œ ì—”íŠ¸ë¡œí”¼ ì¦‰, $1 \cdot \log (p_{y_r}) = 1 \cdot \log (\sigma)$ê°€ ë˜ì–´ì•¼ í•˜ê¸° ë•Œë¬¸ì´ê³  ë°˜ëŒ€ì˜ ê²½ìš°ë„ ë§ˆì°¬ê°€ì§€ì´ë‹¤. 

**DFL** : By substituting $\beta = 0, y_l = y_i, y_r = y_{i+1}, p_{y_l} = P(y_l) = P(y_i) = S_i, p_{y_r} = P(y_r) = P(y_{i+1}) = S_{i+1}$ in GFL, we can have DFL:  
$$DFL(S_i, S_{i+1}) = GFL(S_i, S_{i+1}) = -((y_{i+1} - y) \log{(S_i)} + (y - y_i) \log{(S_{i+1})})$$

# Real-Time Flying Object Detection with YOLOv8
ë³¸ ë…¼ë¬¸ì€ í˜„ì¬ state-of-the-artì¸ YOLOv8ì„ ì´ìš©í•œ ë¹„í–‰ì²´ íƒì§€ëª¨ë¸ì„ ì œì•ˆí•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ Real-time object detectionì€ objectì˜ ê³µê°„ì  ì‚¬ì´ì¦ˆ(spatial sizes), ì¢…íš¡ë¹„(aspect ratios), ëª¨ë¸ì˜ ì¶”ë¡  ì†ë„(inference
speed), ê·¸ë¦¬ê³  noise ë“±ì˜ ë³€ìˆ˜ë¡œ ì–´ë ¤ì›€ì´ ìˆì—ˆë‹¤. ë¹„í–‰ì²´ëŠ” ìœ„ì¹˜(location), í¬ê¸°(scale), íšŒì „(rotation), ê¶¤ë„(trajectory)ê°€ ë§¤ìš° ë¹ ë¥´ê²Œ ë³€í•˜ê¸° ë•Œë¬¸ì— ì•ì„  ë¬¸ì œë“¤ì€ ë¹„í–‰ì²´ë¥¼ íƒì§€í•˜ëŠ”ë° ë”ìš± ë¶€ê°ëœë‹¤. ê·¸ë ‡ê¸°ì— ë¹„í–‰ì²´ì˜ ì´ëŸ¬í•œ ë³€ìˆ˜ì— ëŒ€í•´ thoroughí•˜ê³  ë¹ ë¥¸ ì¶”ë¡ ì†ë„ë¥¼ ê°–ëŠ” ëª¨ë¸ì´ ì¤‘ìš”í–ˆë‹¤. 

<img src="/assets/images/yolov8/plane.png">

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” datasetì¤‘ 80%ë¥¼ train, 20%ì„ validationìœ¼ë¡œ ë‚˜ëˆ„ì—ˆë‹¤. ê° datasetì˜ ì´ë¯¸ì§€ëŠ” class numberê°€ labelë˜ì–´ìˆê³ , bounding box ê°€ì¥ìë¦¬ì˜ ì¢Œí‘œë¥¼ í‘œì‹œí•´ë†¨ë‹¤. í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì—ëŠ” í‰ê· ì ìœ¼ë¡œ 1.6ê°œì˜ objectê°€ ìˆê³ , median image
ratioëŠ” 416x416ì´ë‹¤. ì´ë¯¸ì§€ëŠ” auto orientationìœ¼ë¡œ ì „ì²˜ë¦¬ ë˜ì—ˆìœ¼ë©°, augmentationsì€ ì ìš©í•˜ì§€ ì•Šì•˜ë‹¤. 

##  Model Choice and Evaluation
ë…¼ë¬¸ì—ì„œëŠ” ìš°ì„  YOLOv8ì˜ small, medium, and large ë²„ì „ì— ëŒ€í•´ ìµœì ì˜ inference speedì™€ mAP50-95ë¥¼ ê°–ëŠ” ëª¨ë¸ ë²„ì „ì„ ì„ íƒí–ˆê³ , ì´í›„ì—  hyper parametersë¥¼ ìµœì í™” í–ˆë‹¤. 
VOLOv8ì˜ ê° ë²„ì „ì— ëŒ€í•œ ì •ë³´ëŠ” ì•„ë˜ì™€ ê°™ë‹¤.   
nano (yolov8n), small (yolov8s), medium (yolov8m), large (yolov8l), and extra large (yolov8x)

|Model|Input size(pixels)|mAP50-95|params(M)|FLOPS(B)|
|-|-|-|-|-|
|YOLOv8n|640|37.3|3.2|8.7|
|YOLOv8s|640|44.9|11.2|28.6|
|YOLOv8m|640|50.2|25.9|78.9|
|YOLOv8l|640|52.9|43.7|165.2|
|YOLOv8x|640|53.9|68.2|257.8|

small, medium, large ëª¨ë¸ë“¤ì˜ parametersëŠ” ê°ê° (11151080, 25879480, & 43660680)ì´ê³ , layersëŠ” (225,295, & 365)ì´ë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œ í•™ìŠµì‹œí‚¨ ê²°ê³¼ smallê³¼ medium ì‚¬ì´ì—ì„œëŠ” mAP50-95ì—ì„œ í° ì„±ëŠ¥í–¥ìƒì´ ìˆì—ˆìœ¼ë‚˜ medium, large ì‚¬ì´ì—ì„œëŠ” ê·¸ë ‡ì§€ ì•Šì•˜ë‹¤ê³  í•œë‹¤. ë˜í•œ validation setì— ëŒ€í•´ì„œ small, medium, and largeì˜ inference speedëŠ” ê°ê° 4.1, 5.7, and 9.3 milliseconds ì˜€ë‹¤ê³  í•œë‹¤. ì›ë˜ ëª©í‘œì˜€ë˜ average inference speedëŠ” 30 to 60 frames for 1080pì˜€ê³ , medium size
modelì„ multiple 1080p HD videosì—ì„œ í…ŒìŠ¤íŠ¸í•´ë³¸ ê²°ê³¼ average total speed (pre-proccess speed(0.5ms) + inference speed(17.25ms) + post-process speed(2ms)) of 19.75 ms(50 frames per second)ë¡œ ëª©í‘œì— ì í•©í•˜ì—¬ ëª¨ë¸ì„ medium sizeë¡œ ê²°ì •í•˜ê³  hyper-parameters íŠœë‹ì„ ì§„í–‰í–ˆë‹¤ê³  í•œë‹¤. 

## Loss Function and Update Rule
ë³¸ ë…¼ë¬¸ì—ì„œ ì œì•ˆí•˜ëŠ” Loss Functionì„ ì¼ë°˜í™”í•˜ë©´ ì•„ë˜ì™€ ê°™ë‹¤. 

$$L(Î¸) = \frac{Î»_{box}}{N_{pos}}L_{box}(Î¸) + \frac{Î»_{cls}}{N_{pos}}L_{cls}(Î¸) + \frac{Î»_{dfl}}{N_{pos}}L_{dfl}(Î¸) + Ï†\parallel Î¸\parallel ^2_2$$

$$V^t = \beta V^{t-1} + âˆ‡_Î¸ L(Î¸^{t-1})$$

$$Î¸^t = Î¸^{t-1} - Î·V^t$$

ì²« ë²ˆì§¸ ì‹ì€ ì¼ë°˜í™”ëœ Loss Functionìœ¼ë¡œ box loss, classification loss, distribution focal loss ê°ê°ì˜ Lossë“¤ì„ í•©í•˜ê³ , weight decayì¸ $Ï†$ë¥¼ í™œìš©í•´ ë§ˆì§€ë§‰ í•­ì—ì„œ regularizationì„ í•œë‹¤. ë‘ ë²ˆì§¸ ì‹ì€ momentum $Î²$ë¥¼ ì´ìš©í•œ velocity termì´ë‹¤. ì„¸ ë²ˆì§¸ ì‹ì€ ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ë¡œ $Î·$ëŠ” learning rateì´ë‹¤. 

YOLOv8ì˜ loss functionì„ ìì„¸íˆ ì‚´í´ë³´ë©´ ì•„ë˜ì™€ ê°™ë‹¤. 

$$L = \frac{Î»_ {box}}{N_ {pos}} \sum_ {x, y} ğŸ™_ {c^{\star}_ {x, y}} \left[1 - q_ {x,y} + \frac{\parallel b_ {x, y} - \hat{b}_ {x, y}\parallel ^2_2}{Ï^2} + Î±_ {x, y} v_ {x, y}\right]$$

$$+\frac{Î»_ {cls}}{N_ {pos}} \sum _{x,y} \sum _{c \in classes} y _c log(\hat{y} _c) + (1 - y _c) log(1 - \hat{y} _c)$$ 

$$+\frac{Î»_{dfl}}{N_{pos}} \sum_{x,y} ğŸ™_{c^{\star}_ {x, y}} - \left[(q_ {(x,y)+1} - q_{x,y})log(\hat{q}_ {x,y}) + (q_{x,y} - q_{(x,y)-1})log(\hat{q}_{(x,y)+1})\right]$$

$where:$

$$q_{x,y} = IOU_{x,y} = \frac{\hat{Î²}_ {x,y} âˆ© Î²_{x,y}}{\hat{Î²}_ {x,y} âˆª Î²_{x,y}}$$

$$v_{x,y} = \frac{4}{Ï€^2}(\arctan{(\frac{w_{x,y}}{h_{x,y}})} - \arctan{(\frac{\hat{w}_ {x,y}}{\hat{h}_{x,y}})})^2$$

$$Î±_{x,y} = \frac{v}{1 - q_{x,y}}$$

$$\hat{y}_c = Ïƒ(Â·)$$

$$\hat{q}_{x,y} = softmax(Â·)$$

$and:$

- $N_{pos}$ is the total number of cells containing an object.
- $ğŸ™_{c^{\star}_ {x, y}}$ is an indicator function for the cells containing an object.
- $Î²_{x,y}$ is a tuple that represents the ground truth bounding box consisting of ($x_{coord}, y_{coord}$, width, height).
- $\hat{Î²}_ {x,y}$ is the respective cellâ€™s predicted box.
- $b_{x, y}$ is a tuple that represents the central point of the ground truth bounding box.
- $y_c$ is the ground truth label for class $c$ (not grid cell $c$) for each individual grid cell $(x,y)$ in the input, regardless if an object is present.
- $q_{(x,y)+/-1}$ are the nearest predicted boxes IoUs (left and right) $\in c_{x, y}^*$.
- $w_{x, y}$ and $h_{x, y}$ are the respective boxes width and height.
- $Ï$ is the diagonal length of the smallest enclosing box covering the predicted and ground truth boxes.  




box loss : https://arxiv.org/abs/1911.08287  
class loss : standard binary cross entropy  
distribution focal loss :  https://arxiv.org/abs/2006.04388  


# Reference 
## Web Link 
One-stage object detection : https://machinethink.net/blog/object-detection/  
YOLOv5 : https://blog.roboflow.com/yolov5-improvements-and-evaluation/   
YOLOv8 : https://blog.roboflow.com/whats-new-in-yolov8/       
mAP : https://blog.roboflow.com/mean-average-precision/    
SiLU : https://tae-jun.tistory.com/10     
Weight Decay, BN : https://blog.janestreet.com/l2-regularization-and-batch-norm/  
Focal Loss : https://gaussian37.github.io/dl-concept-focal_loss/  
ã€€ã€€ã€€ã€€ ã€€https://woochan-autobiography.tistory.com/929  
Cross Entropy : https://sosoeasy.tistory.com/351  
DIOU, CIOU : https://hongl.tistory.com/215    
QFL, DFL : https://pajamacoder.tistory.com/m/74  
YOLOv8 Loss ìˆ˜ì • : https://velog.io/@easyssun/YOLOv8-%EB%AA%A8%EB%8D%B8-loss-function-%EC%88%98%EC%A0%95  

## Paper 
Real-Time Flying Object Detection with YOLOv8 : https://arxiv.org/pdf/2305.09972.pdf   
YOLO : https://arxiv.org/pdf/1506.02640.pdf    
YOLOv2 : https://arxiv.org/pdf/1612.08242.pdf    
YOLOv3 : https://arxiv.org/pdf/1804.02767.pdf  
YOLOv4 : https://arxiv.org/pdf/2004.10934.pdf   
YOLOv6 : https://arxiv.org/pdf/2209.02976.pdf  
YOLOv7 : https://arxiv.org/pdf/2207.02696.pdf  
