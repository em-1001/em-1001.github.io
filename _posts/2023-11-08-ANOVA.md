---
title:  "[Statistics] ANOVA"
excerpt: Analysis of Variance (ANOVA)

categories:
  - Statistics
tags:
  - Statistics
toc: true
toc_sticky: true
last_modified_at: 2025-01-19T08:06:00-05:00
---

> 데이터 사이언티스트 되기 책: https://recipesds.tistory.com/

# Analysis

<p align="center"><img src="https://github.com/user-attachments/assets/9bfe042e-ab06-4b33-bb49-51605815032b" height="" width=""></p>

이제부턴 분석에 대해 다룰 것이다. 검정에서 봐왔던 $t$-test도 사실 분석의 일종이라 할 수 있다. 하지만 2개 집단 차이를 볼 때 차이 분석이라 부르지 않고 보통 $t$ 검정이라 한다. 이제 다룰 ANOVA는 분석이라 하는데 $t$ 검정이라 불리는 이유는 검정을 하기 전에 표본 분석을 통한 통계량을 구하기 위해 적당한 Grouping이나 데이터 변환등을 동원해서 데이터 처리를 하는 단계가 있는데, 차이 분석의 경우는 표본을 구하기만 하면 곧바로 검정이 가능하므로 특별하게 분석이라 부르지 않고 그냥 차이 검정 또는 $t$ 검정이라 부른다. 분석의 예를 들면, ANOVA는 분산의 아이디어로부터 표본(원시 (Raw) 데이터)을 분산의 형태로 변환해서, F검정을 하고, 교차분석은 교차표라는 형태로 데이터를 Agrregation 한 후에 카이제곱 검정을 한다. 

## ANOVA

ANOVA(Analysis of Variance)는 분산분석으로 3개 이상의 집단 간 평균의 차이를 검정할 때 사용한다. 평균의 차이를 검정하는데 이름이 분산분석인 이유는 분산의 성질과 원리를 이용한 평균차이 분석이기 때문이다. ANOVA는 평균을 직접 비교하지 않고, 집단내의 분산과 각 집단 간의 평균의 분산을 이용해 평균이 다른지 확인하는 방법이다. 

<p align="center"><img src="https://github.com/user-attachments/assets/96b8aa71-4d62-4f2d-89ca-115a656d6ed3" height="" width=""></p>

3개의 집단이 있다고 할 때, 위 그림을 통해 알 수 있듯이 집단 평균 간의 분산이 크고, 집단 내의 분산이 작으면 평균이 서로 확실히 다르다는 것을 알 수 있다. 위 그림에서는 3번 케이스를 제외하고는 평균이 다르다고 단정 지을 수 없다. ANOVA의 기준은 집단간 평균의 분산이 커지고, 집단 내 분산이 작아지는 3번의 경우를 기준으로 찾아낼 수 있고, 이러한 경향이 커질수록 통계량 값은 커진다. 따라서 평균 제곱 간의 비를 (집단 간 평균의 분산 / 집단 내 분산) 으로 정의할 수 있다. 이때의 검정 통계량 $F$는 $F$ 분포를 따르고, 이 차이가 통계적으로 유의한 지를 분석해서 평균이 모두 같다는 귀무가설을 검증하면 된다. 

분산 자체는 $\chi^2$ 카이스퀘어 분포를 따르는데, 분자 분모가 모두 카이스퀘어 분포를 따르는 경우에 이런 비율이 따르는 분포는 $F$ 분포를 따른다. 따라서 ANOVA에서는 $F$ 분포를 사용한다. 우리가 이용하는 F분포는 Null Hypothesis가 집단간 평균이 같을 경우의 F값(통계량)의 분포이다. 만약 F분포에서 관측된 F값(통계량)으로 p값을 계산해 보았는데 p값이 너무 작은 경우에는 평균이 서로 같은 환경에서 관측하기 어려운 것이므로 집단 중에 최소한 1개는 평균이 다르다라고 결론을 낼 수 있다. 

통계량은 앞서 (집단 간 평균의 분산 / 집단 내 분산)를 (Between Mean Variance/ Within Variance)로 표현한다. 이 의미는 Between Mean Variance가 Within Variance에 비해 크면 최소한 1개 그룹은 차이가 난다고 할 수 있다. 그러므로 $F = \frac{Mean_{Between}}{Mean_{Within}}$ 을 (설명된 분산 / 설명되지 않은 분산) 으로 표기하는데, 설명된 분산이란 이미 계산할 값들이 정해지는 경우이고, 설명되지 않은 분산이란 계산 시 경우에 따라 Random 하게 다르게 정의하고, 자유도는 Between의 경우 k group-1, Within의 경우 n-k (sample-group)이 된다. 두 자유도의 합은 n-1이 되며, 이유는 k 그룹으로 mean을 구했으니 k-1 자유도가 되고, Within의 경우 전체 n 개에서 k개 그룹의 mean을 이미 구했으므로 n-k가 된다. 

예를 들어서 남학생, 여학생, 외계인 학생의 발 길이에 대한 데이터가 있다고 하자. 

boy = [27.3, 28.5, 29.7]  
girl = [23.5, 24.2, 22.2, 25.7]   
alien = [19.2, 18.6, 17.1]   

이 데이터를 기반으로 각 집단의 평균에 대한 분산(Between), 각 집단 내 평균에 대한 분산(Within)을 구하면 다음과 같다. 

<p align="center"><img src="https://github.com/user-attachments/assets/5ebb0554-25b1-4b89-91ac-f84731b675d9" height="" width=""></p>

$$F = \frac{⓵/dof_{between}}{⓶/dof_{within}} = \frac{156.66/2}{11.6/7} = 47.268$$

결국 집단별 표본평균의 분산은 중심극한정리에 의해 $\sigma_x = \frac{\sigma}{\sqrt{n}}$ 이므로, $\sigma^2 = n\sigma_x^2$이 되고, 표본분산을 이용해 추정한 모분산은 $\sigma^2 = ns_x^2$ 가 되므로, ⓵은 각각의 집단의 표본평균의 분산을 각각 구해서 더한 것 즉, $3 \times (28.5-23.6)^2 + 4 \times (23.9 - 23.6)^2 + 3 \times (18.3 - 23.6)^2$이고, 결국 집단 수에 대한 자유도로 평균을 낸 값이다. ⓶는 집단내 편차들의 전체 제곱합으로, 단순하게 각 집단 내의 모든 편차 제곱을 다 더해서 자유도로 평균낸 값이다. 

5% 유의수준으로 검정해보면, 유의 수준 5% 일 때의 F값을 F테이블을 이용해서 구해보면 4.74이다. 

<p align="center"><img src="https://github.com/user-attachments/assets/de65247e-959d-455e-a185-30b568178028" height="" width=""></p>

<p align="center"><img src="https://github.com/user-attachments/assets/426d8d82-f0dc-408e-ae5e-e40cff335881" height="" width=""></p>

결과적으로 p value가 매우 작으므로 귀무가설은 기각되어 3개의 그룹은 차이가 있다고 결론지을 수 있다. 

파이썬을 이용하면 다음과 같다. 

```py
from scipy import stats
 
boy = [27.3, 28.5, 29.7]
girl = [23.5, 24.2, 22.2, 25.7]
alien = [19.2, 18.6, 17.1] 
 
stats.f_oneway(boy, girl, alien)

> F_onewayResult(statistic=47.26810344827576, pvalue=8.603395069970194e-05)
```

여기서 one way는 일원분산분석이라고 해서 one way AVONVA라 한다. 이 의미는 우리가 비교하려는 요인의 개수가 1개라는 의미이다. 
그룹(집단)을 군 또는 수준 이라고도 하고, 요인은 각 그룹(집단)을 구분짓게 하는 것인데, 실험요인/인자/독립변수(Factor) 라고도 한다. 
발길이에 대한 예를 다시 한번 살펴보면 group(boy, girl, alien)이 독립변수, 발길이가 종속변수. 즉, group에 따라 발길이가가 달라지는지 1개의 독립변수와 1개의 종속변수를 검정한 것이라고 할 수 있다.

다른 예를 들어 한 마케팅연구에서 30명의 표본을 선정한 후 이들을 임의로 세 가지 형태의 콜라 광고 중 하나를 시청하게 하였다. 1시간 동안 시청하게 한 후, 광고에 반응하는 것(구매욕구)을 측정하여 세 가지 광고의 차이가 있는지 알고자 할때, 

측정값 : 구매욕구 (종속변수)  
요인 : 광고 (독립변수)  
수준 : 3가지 광고   

가 된다. 광고에 따라 구매욕구가 달라지는가를 연구할 떄, one way ANOVA를 한다고 할 수 있다. 
여기에 광고에 따라 그리고, 남/여에 따라 어떻게 되는지 확인하게 되면 two way ANOVA가 된다. 

<p align="center"><img src="https://github.com/user-attachments/assets/155ae5df-978e-4d3a-9207-c4dd832eb6c9" height="" width=""></p>

3개 이상의 집단끼리 차이를 분석할 때, 2개씩 짝이어서 t 검정을 하지 않고 ANOVA를 쓰는 이유는, 예를 들어 3개 그룹을 비교할 때는 3가지 짝지움을 할 수 있다. 이때, 1개의 짝지움에 대해 t Test를 하는 경우에는 α=5%로 보았을 때에는 잘못 판단하지 않을 확률이 95%이다. 이제 3번을 연속해서 검정하게 되는데, 유의하지 않을 확률  95%, 유의할 확률 5%의 동전을 던진다고 할 때, 3번 연속해서 동전을 던진 후에 한 번도 유의하지 않을 확률은 95% x 95% x 95%이다. 따라서  최소한 한 번이라도 유의할 확률은 1 - 95% x 95% x 95%가 된다. 이렇게 되면 원래 α는 5%로 시작했지만 3번 연속 검정을 하게 되면 1 - 95% x 95% x 95% = 0.142625가 되어 약 14.2%정도로 α가 커진다. 이렇게 되면 원래 5%로 판단하려고 했던 처음 의도와 다르게 14.2%를 기준으로 유의성을 판단하는 것과 같은 효과가 된다. 이를 일반화 하면, 전체 그룹에서 2개를 뽑는 경우만큼 t test를 하고, 신뢰도는 1-α이므로 $1 - (1 - \alpha)^{_{n}C _{2}}$ 가 된다. 이렇게 되었을 때 유의확률α가 커지니까 False Positive 오류 (Type I Error)를 범할 확률이 커지게 된다. 

추가적으로 2개 그룹의 평균을 비교할 때 t test 대신 ANOVA를 써도 된다. 등분산의 2개 집단에 대해 Independent two Samples t-test결과와 ANOVA결과는 p value가 똑같이 나온다. 게다가 두 분석의 통계량은 제곱 관계로서, t값을 제곱하면 F값이 나온다. 

ANOVA는 분산의 동질성(모분포에 대해)이 매우 중요하다. 이 분산의 동질성 가정을 만족하지 못하는 경우에는, Welch 검정을 하게된다. 


## Post Hoc

Post Hoc(사후분석)은 ANOVA에서 유의(Significant)하다는 검정 결과가 나왔을 때, 집단 중 어느 집단이 다른 것인가를 찾아내는 것이다. 
ANOVA의 Alternative Hypothesis는 최소한 1개의 집단은 평균이 다르다이므로 어느 것이 다른지를 찾아야 한다. 앞서 말했듯이 t test를 $_{n} C _{2}$번 해서 찾아내는 것은 $1 - (1 - \alpha)^{ _{n}C _{2}}$ 로 유의수준이 커지므로 Type I Error가 늘어난다. 

사후분석을 위한 방법에는 Fisher's LSD(피셔의 LSD), Tukey' HSD 투키의 HSD), Bonferroni correction (봉페로니교정), Duncan (던칸의 방법), Scheffe (셰페의 방법), Games Howell (게임즈 하웰) 등이 있고, 이런 분석들을 통틀어 Post Hoc이라 한다. 이러한 사후분석들은 모두 등분산을 가정하고 차이는 다음과 같다. 

1. Fisher's LSD: 집단을 짝지어 t test를 아무 보정 없이 하는 방법으로 좋은 방법이 아니다.
2. Tuckey' HSD: 비교 집단간 표본크기가 동일한 경우 사용하고, t분포를 사용한다.
3. Bonferroni: t검정을 짝지어서 검정한 후 유의수준 $\alpha$를 5%로 보정한다. 보정된 유의수준은 FWE라 부른다.
4. Duncan: Duncan은 작은 차이에도 차이가 난다고 결과를 낸다. 집단 간 차이가 꼭 드러나야 하는 경우 사용하는 것이 좋고, 사회과학 등에서 설문을 할 때 많이 사용한다.
5. Sheffe: 큰 차이가 나야 차이가 난다고 결과를 낸다. F분포를 활용해 검정한다.

위는 일반적인 ANOVA의 Post Hoc이고, 등분산이 아닌 경우 Welch 검정을 하는데 이 경우에는 Games Howell를 사용한다. Games Howell는 Welch의 방법으로 t분포의 자유도를 바꿔서 검정한다. 

만약 ANOVA에서 유의하다고 결과가 나왔는데, Post Hoc에서 유의하지 않다고 나올 수도 있다. 즉, ANOVA에선 차이가 있다고 해놓고 막상 어떤 집단이 다른지 모르는 경우엔 집단 간 차이가 유의한 것으로만 단순 해석하는 것이 합리적이다. 

앞서 발길이 예시로 실제 검정을 해보면 다음과 같다. 

```py
boy = [27.3, 28.5, 29.7]
girl = [23.5, 24.2, 22.2, 25.7]
alien = [19.2, 18.6, 17.1]
```

1.정규성 검정(Shapiro-Wilk)

```py
from scipy.stats import shapiro
 
boy = [27.3, 28.5, 29.7]
girl = [23.5, 24.2, 22.2, 25.7]
alien = [19.2, 18.6, 17.1] 
 
print(shapiro(boy))
print(shapiro(girl))
print(shapiro(alien))
 
>
ShapiroResult(statistic=1.0, pvalue=0.9999986886978149)
ShapiroResult(statistic=0.9968306422233582, pvalue=0.9891670346260071)
ShapiroResult(statistic=0.9423076510429382, pvalue=0.5367357134819031)
```

세 집단 모두 정규성 검정을 통과한다. 사실 표본이 작기 때문에 큰 의미는 없고, 모집단이 정규성을 띄므로 표본의 평균도 정규적이라고 가정할 수 있다. 

2.등분산성 검정(Levene, Bartlett)

```py
from scipy.stats import levene, bartlett
 
print(levene(boy, girl, alien))
print(bartlett(boy, girl, alien))
 
>
LeveneResult(statistic=0.19816176470588293, pvalue=0.8246838520550716)
BartlettResult(statistic=0.19083867589274103, pvalue=0.9089916798322615)
```

Levene과 Bartlett에서 모두 등분산 검정을 통과하므로 3개의 집단이 모두 모분산이 동질하다고 할 수 있다. 

3.One way ANOVA

```py
from scipy.stats import f_oneway
 
f_oneway(boy, girl, alien)
 
>
F_onewayResult(statistic=47.26810344827576, pvalue=8.603395069970194e-05)
```

유의하다는 결과가 나오므로 세 집단에 차이가 있다.   

이제 어느 집단이 다른지 확인할 수 있도록 Post Hoc을 해보면 표본의 크기가 서로 다르므로 Bonferroni를 사용한다. 
Bonferroni를 하기 전에 데이터의 모양새가 값과 그룹의 종류에 대한 데이터를 순서를 맞추어 넣으면 pandas dataframe로 다음과 같다. 

```py
import pandas as pd
 
lst_value = boy + girl + alien
lst_group = ["boy" for i in range(len(boy))] + ["girl" for i in range(len(girl))] + ["alien" for i in range(len(alien))]
df_total = pd.DataFrame({'Group':lst_group, 'Value':lst_value}).reset_index(drop=True)
print(df_total)
 
>
    Group  Value
0    boy   27.3
1    boy   28.5
2    boy   29.7
3   girl   23.5
4   girl   24.2
5   girl   22.2
6   girl   25.7
7  alien   19.2
8  alien   18.6
9  alien   17.1
```

이렇게 데이터를 만들어야 Bonfrroni를 할 수 있다. 

```py
from statsmodels.sandbox.stats.multicomp import MultiComparison
from scipy.stats import ttest_ind
 
comp = MultiComparison(df_total['Value'], df_total['Group'])
ret = comp.allpairtest(scipy.stats.ttest_ind, method='bonf')
print(ret[0])
 
>
Test Multiple Comparison ttest_ind 
FWER=0.05 method=bonf
==============================================
group1 group2   stat    pval  pval_corr reject
----------------------------------------------
 alien    boy -10.9355 0.0004    0.0012   True
 alien   girl  -5.5521 0.0026    0.0078   True
   boy   girl   4.4257 0.0069    0.0206   True
----------------------------------------------
```

pval_corr이 집단의 개수로 곱해진 보정된 p value이고, 모두 유의하다는 것을 알 수 있다. 따라서 서로 모두 차이가 있다. 










