---
title:  "[Statistics] Bayesian I"
excerpt: Bayesian statistic

categories:
  - Statistics
tags:
  - Statistics
toc: true
toc_sticky: true
last_modified_at: 2025-01-19T08:06:00-05:00
---

> 데이터 사이언티스트 되기 책: https://recipesds.tistory.com/

# Bayesian Statistic

고전 통계학의 빈도주의적 접근은 관측된 현상(phenomena)이 '우리가 알지 못하는 고정된 프로세스'로부터 발생한 것이라 가정하고, 그 현상을 분석하는 통계학이다. 반면 베이지안 관점은 확률을 믿음(신념)의 정도로 나타낸 후, 새로운 사건을 관츰함에 따라 믿음의 정도(확률)을 갱신하는 것으로 통계에 대한 모수를 고정된 상수로 보는 빈도주의 접근과 달리 모수를 확률변수로 인식한다. 

## Conditional probability

A가 일어난 상황에서 B의 확률이란 A가 일어난 상황으로 "한정"해서, 즉 A가 일어난 상황이 Sample Space(전체집합, 분모)으로 바뀌고, 이때 B가 일어난 상황이라고 해석이 바뀌어야 한다. 결국 Conditional Probability는 Conditional부분이 전체집합으로 치환, 한정되는 확률이라고 보면 된다. 

간단한 Conditional Probability의 예를 살펴보자. 

어느 대학교의 경영학과에는 남자가 50%로 있고, 남자 중에 A학점의 남자가 40%, 여자 중에 A학점의 여자가 60%가 있다고 하자. 이때 임의로 뽑은 사람이 A학점일 때 이 사람이 남자일 확률은 얼마인가?

수식으로 표현하면 다음과 같다. 

<p align="center"><img src="https://github.com/user-attachments/assets/8a91910c-2679-4b44-9c27-34873ff97f11" height="" width=""></p>

결국엔 분모는 전체  A학점수를 구하는 거고, 분자는 그중 남자가  A학점인 경우를 구하는 것이다. 

이걸 확률로 쓰지않고 다음과 같이 비율로 접근할 수도 있다. 그냥 전체 집합을 100명이라 생각하는 것이다. 

<p align="center"><img src="https://github.com/user-attachments/assets/a2c3c9ee-e9ba-4587-96dd-9fafbed0f00b" height="" width=""></p>

## Bayesian inference

베이즈 정리는 H와 D의 Notation으로 많이 표시하는데, H는 Hypothesis, 즉, 가정을 의미하고, D는 Data 즉 관측치를 의미한다. 

조건부 확률을 표시하면 다음과 같다. 

$$P(H \vert D) = \frac{P(D \cap H)}{P(D)}$$

이때 $P(D \vert H) = \frac{P(D \cap H)}{P(H)}$이므로 이걸 이용해 교집합을 다시 풀어 쓰면 다음과 같다. 

$$P(H \vert D) = \frac{P(D \cap H)}{P(D)} = \frac{P(D \vert H)P(H)}{P(D)}$$

좌변과 우변을 잘 보면 $P(H)$가 $P(H \vert D)$가 되는 것이다. 

각 Term들을 살펴보면 다음과 같다. 

$$\frac{P(H) \cdot P(Data \vert H)}{P(Data)} = P(H \vert Data)$$

$P(H \vert Data)$: 사후 확률(Posterior Probability)- Data를 고려한 후의 가설이나 사건의 갱신된 확률    
$P(Data \vert H)$: 우도(Likelihood) - 특정 가설이나 모델로 관측된 데이터를 설명할 수 있는 정도  
$P(H)$: 사전확률(Prior Probability) - Data를 고려하기 전의 사건에 대한 초기 믿음 또는 확률  

$\frac{P(H) \cdot P(Data \vert H)}{P(Data)}$의 의미는 초기 믿음 또는 확률 $P(H)$에 그런 믿음하에 데이터가 발생할 확률 $P(Data \vert H)$을 곱한 뒤 이 값을 데이터가 나올 확률 $P(Data)$로 나누어 크기를 조정한 것이다. 이를 Normalize라고도 한다. 결과적으로 $P(H) \to P(H \vert Data)$의 의미는 원래 확률 $P(H)$이 데이터를 관측함으로써 어떻게 갱신되었는가? $P(H \vert Data)$를 알 수 있게 된다. 

우도(Likelihood)에 대해 좀 더 설명하면 이전에 살펴보았던 최대 우도 추정법(MLE)에서 $P(data \vert \theta)$가 우도였는데, 이는 모분포와 그에 대한 모수 $\theta$를 가정한 후 Data가 관측될 강도를 의미했다. 베이지안에서 이를 약간 확대해서 해석하면 prior를 가정한 후에 prior조건하에 Data가 관측될 확률이므로 같은 맥락이라 할 수 있다. 

다음 동전던지기 예로 베이지안 관점에서 확률이 어떻게 갱신되는지 살펴보자. 

동전 던지기를 할 때, 느낌상 100번을 던지면 60번은 앞면이 나오는 거 같다고 치자. 그래서 동전이 Unfair하다고 생각한다면, 동전이 Unfair할 확률은 0.6이 된다. 그러면 $P(H) = P(Unfair) = 0.6$이고, Fair할 확률은 $P(Fair) = 0.4$가 된다. 여기서 동전이 Fair하다는 것은 앞면과 뒷면이 나올 확률이 0.5로 같다는 것이다. Unfair할 경우 앞면이 나올 경우는 0.6이라 하자. 

동전을 한 번 던졌을 때 앞면이 나왔을 경우, 동전이 Unfair하다는 믿음이 갱신되는 과정을 살펴보자. 

$$\begin{align}
P(Unfair) &= 0.6 \\ 
P(Data \vert Unfair) &= 0.6 \\ 
P(Data) &= 0.4 \times 0.5 + 0.6 \times 0.6 \\ 
\end{align}$$

$$P(Unfair \vert Data) = \frac{P(Unfair) \cdot P(Data \vert Unfair)}{P(Data)} = 0.6429$$

원래 0.6이었던 $P(H) = P(Unfair) = 0.6$가 Data를 반영한 뒤 갱신되어 $P(H \vert Data) = P(Unfair \vert Data) = 0.6429$로 높아진 것을 확인할 수 있다. 

동전을 두 번 던졌을 때 두 번 모두 앞면이 나왔을 경우, Unfair 믿음이 갱신되는 과정은 다음과 같다. 

$$\begin{align}
P(Unfair) &= 0.6 \\ 
P(Data \vert Unfair) &= (0.6 * 0.6) \\ 
P(Data) &= 0.4 \times (0.5 \times 0.5) + 0.6 \times (0.6 \times 0.6) \\ 
\end{align}$$

$$P(Unfair \vert Data) = \frac{P(Unfair) \cdot P(Data \vert Unfair)}{P(Data)} = 0.6835$$

두 번 모두 앞면이 나온경우 Unfair에 대한 믿음이 더욱 강해지는 것을 확인할 수 있다.     
베이지안 확률에서는 이런 식으로 데이터를 관측하면서 확률을 갱신하는 방식을 사용한다. 

몇가지 예를 더 살펴보자. 다음은 암 진단 오진율과 조건부확률에 관한 문제이다. 

암 진단 키트가 있는데, 성인 중 0.1%가 암에 걸려있다고 하자. 이때 검사는 95%를 발견하고, 오발견은 10%라고 한다. 이때 어떤 사람의 검사 결과가 암이라고 했을 때, 실제로 암에 걸렸을 확률은? 

주어진 정보는 양성을 관측했고(Data), Prior가 성인중 0.1% 확률이라는 점이고, 이 Prior가 참이라는 가정아래 양성을 볼 확률 95%가 Likelihood라는 것이다. 

암을 H, 양성을 +로 표기하면, Tree 형태로 문제를 풀 수 있다. Tree의 시작은 관측사건을 두고, 그 다음에는 Prior와 Prior의 여집합 등으로 Tree를 만든다. Tree의 마지막에는 Prior에 따른 관측사건에 대한 확률을 늘어놓고, 이것이 Likelihood이다. 

<p align="center"><img src="https://github.com/user-attachments/assets/9bdc4e11-e1fe-428e-a960-bcdab283924f" height="" width=""></p>

결국 문제의 상황을 계산하면 다음과 같다. 

$$P(H \vert +) = \frac{P(+ \vert H)P(H)}{P(H)} = \frac{0.001 \times 0.95}{0.001 \times 0.95 + 0.999 \times 0.1} = 0.94\%$$

0.1%에서 키트에서 양성이라고 판단할 경우 0.94%로 갱신된다. 

다른 경우를 살펴보자. 어떤 봉지 안에 A항아리와 B항아리가 들어있고, A항아리와 B항아리가 선택되는 비율은 7:3이다. A항아리에는 흰 공이 2개 검은 공이 8개 있고, B항아리에는 흰 공이 9개 검은 공이 6개 있다. 이때 공 하나를 꺼내봤더니 흰 공이 나왔다고 할 때 어떤 항아리에서 흰 공이 나왔을 확률이 더 큰지 판단해보자. 

흰 공을 봤으므로 흰 공이 Data가 되고, 그때 항아리 A와 B를 각각 Prior로 두고 계산하면 된다. 항아리 A를 기준으로 항아리 A일 확률이 Prior, 항아리 A일 때 흰 공을 볼 확률이 Likelihood가 된다. 

tree를 채워보면 다음과 같다. 

<p align="center"><img src="https://github.com/user-attachments/assets/b55c0794-a44a-443b-8204-0f2919feaba4" height="" width=""></p>

흰 공을 W, 검은 공을 B라 할 때 우리가 비교해야 하는 두 확률은 다음과 같다. 

$$P(A \vert W) = \frac{P(W \vert A)P(A)}{P(W)}$$

$$P(B \vert W) = \frac{P(W \vert B)P(B)}{P(W)}$$

이를 $\frac{P(A \vert W)}{P(B \vert W)}=\frac{P(W \vert A)P(A)}{P(W \vert B)P(B)}$로 계산하여 1보다 큰지 작은지 확인하면 된다. 

## Non-informative distribution

분포에 대한 정보가 없는 상황에서 베이즈 추정을 이용해 모수분포를 추론하는 과정을 살펴보자. 무정보 분포로부터 데이터를 관측할 때 마다 모수에 대한 확률분포가 어떤 식으로 변해가는지를 볼 것이다. 

동전 던지기를 예로 들어서 동전에서 앞면이 나올 확률의 분포를 추정할 것이므로 즉, 확률의 확률을 따질 것이므로 앞면이 나올 확률인 $p$는 모수로써 이 $p$를 $\theta$라 설정할 것이다. 

문제를 설정하면 앞면이 나올 확률이 $\theta$인 동전을 던져서 관찰했는데, 앞면, 앞면, 뒷면이 나왔다고 하자. 이때 앞면이 나올 확률 $\theta$가 어떤 식으로 변화하는지 확인해보자. 

지금 당장은 이 동전의 앞면이 나올 확률 θ에 대한 정보가 아무것도 없기 때문에 θ는 0 ~ 1의 Uniform 분포를 갖는다고 가정하고 변화를 유도해 볼 것이다. 물론 θ는 확률이므로 0 ~ 1사이의 값을 갖는다. 

<p align="center"><img src="https://github.com/user-attachments/assets/f36a18d5-da5a-4b33-937d-317bed9b6c95" height="" width=""></p>

이때에는 Prior가 Uniform이니까 늘 θ=1 이 된다. 처음으로 앞면을 봤다고 했다. 따라서 $P(H \vert \theta)$는 앞면이 나올 확률이 $\theta$일 때 앞면이 나올 확률이므로 $\theta$이다. 이제 H가 앞면(Head), T가 뒷면(Tail)이라 할 때 베이즈 정리를 이용하면 다음과 같다. 

$$P(\theta \vert H) = \frac{P(H \vert \theta)P(\theta)}{P(H)}$$

따라서 계산하면 다음과 같이 된다. 

$$P(\theta \vert H) = \frac{\theta \cdot 1}{P(H)} = \frac{\theta}{P(H)} = C \theta$$

여기서 1/P(H)는 그냥 상수로 $\theta$의 범위가 0~1이고, 확률의 면적이 1이라는 것을 이용해서 다음과 같이 구한다. 

$$\int_{0}^{1} P(\theta \vert H), d\theta = \int_{0}^{1} C \theta, d\theta$$ 

결국 C=2가 되고 앞면을 관측했을 때의 분포가 다음과  같이 된다. 

<p align="center"><img src="https://github.com/user-attachments/assets/028322ed-af9a-4501-8b7d-c338039cbc07" height="" width=""></p>

두번째도 앞면을 보았다. 이번에는 Prior가 $2\theta$가 되고, $P(H \vert \theta)=\theta$이다. Posterior를 계산하면 다음과 같다. 

$$P(\theta \vert H) = \frac{\theta \cdot 2\theta}{P(H)} = \frac{2\theta^2}{P(H)} = C\theta^2$$

위와 같은 방식으로 $\theta$의 범위와 확률면적이 1임을 이용해 C를 구하면 다음과 같다. 

$$\int_{0}^{1} C^2\theta^2, d\theta = C \frac{1}{3} = 1 \ \therefore C=3$$

결국 $P(\theta \vert H) = 3\theta^2$가 된다. 

<p align="center"><img src="https://github.com/user-attachments/assets/e49227db-c18e-4c22-9490-d2605d1c0df5" height="" width=""></p>

모양새가 앞면이 나올수록 다른 값에서의 확률밀도가 줄고 1에서 더 최대가 된다. 

마지막으로 관측한 값은 뒷면이다. 이때 Prior는 $3\theta^2$이고, Likelihood $P(T \vert \theta)$는 $(1-\theta)$이다. Posterior를 계산하면 다음과 같다. 

$$P(\theta \vert T) = \frac{(1-\theta) \cdot 3\theta^2}{P(T)} = C(1-\theta)\theta^2$$ 

$$\int_{0}^{1} C(1-\theta)\theta^2, d\theta=1 \ \therefore C=12$$

<p align="center"><img src="https://github.com/user-attachments/assets/291279d2-29ad-4c85-afec-3a614cc9fb00" height="" width=""></p>

분포를 보면 2/3지점에서 $\theta$가 최대가 된다. 여기서 Maximum A Posterior Posterior를 잠깐 언급하면, 2/3 지점에서 Posterior Probability가 최대가 된다는 것이 바로 MAP이다. 

추가적으로 베이지안 통계를 더 파다보면 베타분포를 만나게 되는데, Uniform 분포는 베타분포의 특수한 경우 Beta(1,1)이다. 베타분포는 확률의 확률을 표현할 때 유용하며, 위 예시처럼 $\theta$가 확률인 경우 그런 $\theta$의 분포를 설명하는 초기 분포로 Uniform를 썼는데 이게 베타분포이다. 

## Beta distribution

$\beta$분포의 pdf는 다음과 같다. 

$$\begin{align}
C \cdot x^{a-1} (1-x)^{b-1} &= \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} x^{a-1} (1-x)^{b-1} \\ 
&= \frac{1}{B(a,b)} x^{a-1} (1-x)^{b-1} \sim \beta(a, b)
\end{align}$$

$\beta$분포는 Bernoulli나, Binomial처럼 성공/실패에 대한 이항 결과에 대한 확률 분포를 다루는 것인데, Bernoulli와 Binomial처럼 성공의 횟수가 확률 변수가 아니라 성공의 비율을 확률 변수로 다룬다. 따라서 $\beta$분포를 통해 성공의 비율에 대한 확률을 알아낼 수 있다. 

예를 들어,  Binomial의 경우 p가 주어져 있고, $X=k$번 성공 확률의 distribution은 $P(X \vert p) \sim B(n, p)$이다. 반면에 거꾸로 $a$번 성공, $b$번 실패일 때 $p$의 distribution은 $p \sim \beta(a, b)$를 따른다. 즉 관측된 데이터를 보고 $p$의 분포를 따져보는 것으로 $p$자체가 random variable이 된다. 그래프로 x축은 비율(확률)이 되고, y축은 그 비율(확률)일 확률이 된다. (x축은 0~1이다.)

$\beta$분포의 Mode(최빈값)은 성공과 실패의 비율로 결정되는데, $a$ 성공, $b$ 실패에 대해 최빈값은 다음과 같다. 

$$mode = \frac{a -1}{a + b -2}$$

<p align="center"><img src="https://github.com/user-attachments/assets/e0a88986-8d76-4d82-a92a-5bd5ef5afb44"></p>

$\beta$분포는 최빈값에서 가장 밀도가 크게 나타나며, 성공인 $a$가 클수록 0.5보다 오른쪽에, 실패인 $b$가 클수록 0.5보다 왼쪽에 밀도가 높게 나타난다. 또한 $a$, $b$값이 커질수록 sharp한 모양이 된다. 

$\beta$분포는 Bernoulli, Binomial, Negative Binomial, Geometric distribution에 대해서 conjugate prior하다. 예를 들어 Binomial의 모수를 추정하는 데 있어 $\beta$분포가 사전 분포로써 이용될 수 있는데, Bernoulli, Binomail, Negative Binomial, Geometric 분포에 대한 Bayesian 모수 추정을 할 때 $\beta$를 모수에 대한 prior로 두면 post도 $\beta$분포가 나와 쉽게 해당 분포의 모수를 추정할 수 있다. 이는 베이지안 추정을 하면서 prior와 posterior 분포가 같아 prior와 posterior 분포의 변화를 살펴볼 수 있게된다. 

$$f(x) = \binom{n}{k} p^x (1-p)^{n-x}$$

$$f(p) = \frac{\Gamma(a+b)}{\Gamma(a)\Gamma(b)} p^{a-1}(1-p)^{b-1}$$

감마($\Gamma$)는 팩토리얼연산의 일반형이다. $p$를 random variable로 둔 이유는 베이지안에서는 모수가 상수가 아니라 random variable이기 때문이고, 이러한 random variable을 다루기 위해 $\beta$분포를 사용한다. 

Likelihood를 Binomial로, Prior를 $f(p) \sim \beta(a, b)$라 하면, 베이즈 룰은 다음과 같다. 

$$P(p \vert X = k) = \frac{P(X=k \vert p) \cdot f(p)}{p(X=k)} = \frac{_{n}C _{k}p^k(1-p)^{n-k} \cdot C p^{a-1}(1-p)^{b-1}}{P(X=k)}$$

$p$와 관련되지 않은 값들을 모두 constant로 생각하고 배제하면, $p^{a+k-1}(1-p)^{b+n-k-1}$에 proportional하다. 

$$P(p \vert x=k) \propto \beta(a+k, b+n-k)$$

Likelihood를 Binomial로 놓았을 때, Bayesian rule을 이용해서 post를 계산하니, 다시 $\beta$ Distribution이 나오는 것을 확인할 수 있다. 이러한 특성을 prior conjugate라 한다. 위의 경우 $a$번 성공, $b$번 실패였다면,  Likelihood에서 관측한 $k$번 추가 성공, $n-k$번 추가 실패라 할 수 있다. 이를 일반화 해서 다음과 같이 표현한다. 

$$P(p \vert x = X) \propto \beta(a + X, b + n - X)$$
