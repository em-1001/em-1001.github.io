---
title:  "[Statistics] Bayesian I"
excerpt: Bayesian statistic

categories:
  - Statistics
tags:
  - Statistics
toc: true
toc_sticky: true
last_modified_at: 2025-01-19T08:06:00-05:00
---

> 데이터 사이언티스트 되기 책: https://recipesds.tistory.com/

# Bayesian Statistic

고전 통계학의 빈도주의적 접근은 관측된 현상(phenomena)이 '우리가 알지 못하는 고정된 프로세스'로부터 발생한 것이라 가정하고, 그 현상을 분석하는 통계학이다. 반면 베이지안 관점은 확률을 믿음(신념)의 정도로 나타낸 후, 새로운 사건을 관츰함에 따라 믿음의 정도(확률)을 갱신하는 것으로 통계에 대한 모수를 고정된 상수로 보는 빈도주의 접근과 달리 모수를 확률변수로 인식한다. 

## Conditional probability

A가 일어난 상황에서 B의 확률이란 A가 일어난 상황으로 "한정"해서, 즉 A가 일어난 상황이 Sample Space(전체집합, 분모)으로 바뀌고, 이때 B가 일어난 상황이라고 해석이 바뀌어야 한다. 결국 Conditional Probability는 Conditional부분이 전체집합으로 치환, 한정되는 확률이라고 보면 된다. 

간단한 Conditional Probability의 예를 살펴보자. 

어느 대학교의 경영학과에는 남자가 50%로 있고, 남자 중에 A학점의 남자가 40%, 여자 중에 A학점의 여자가 60%가 있다고 하자. 이때 임의로 뽑은 사람이 A학점일 때 이 사람이 남자일 확률은 얼마인가?

수식으로 표현하면 다음과 같다. 

<p align="center"><img src="https://github.com/user-attachments/assets/8a91910c-2679-4b44-9c27-34873ff97f11" height="" width=""></p>

결국엔 분모는 전체  A학점수를 구하는 거고, 분자는 그중 남자가  A학점인 경우를 구하는 것이다. 

이걸 확률로 쓰지않고 다음과 같이 비율로 접근할 수도 있다. 그냥 전체 집합을 100명이라 생각하는 것이다. 

<p align="center"><img src="https://github.com/user-attachments/assets/a2c3c9ee-e9ba-4587-96dd-9fafbed0f00b" height="" width=""></p>

## Bayesian inference

베이즈 정리는 H와 D의 Notation으로 많이 표시하는데, H는 Hypothesis, 즉, 가정을 의미하고, D는 Data 즉 관측치를 의미한다. 

조건부 확률을 표시하면 다음과 같다. 

$$P(H \vert D) = \frac{P(D \cap H)}{P(D)}$$

이때 $P(D \vert H) = \frac{P(D \cap H)}{P(H)}$이므로 이걸 이용해 교집합을 다시 풀어 쓰면 다음과 같다. 

$$P(H \vert D) = \frac{P(D \cap H)}{P(D)} = \frac{P(D \vert H)P(H)}{P(D)}$$

좌변과 우변을 잘 보면 $P(H)$가 $P(H \vert D)$가 되는 것이다. 

각 Term들을 살펴보면 다음과 같다. 

$$\frac{P(H) \cdot P(Data \vert H)}{P(Data)} = P(H \vert Data)$$

$P(H \vert Data)$: 사후 확률(Posterior Probability)- Data를 고려한 후의 가설이나 사건의 갱신된 확률    
$P(Data \vert H)$: 우도(Likelihood) - 특정 가설이나 모델로 관측된 데이터를 설명할 수 있는 정도  
$P(H)$: 사전확률(Prior Probability) - Data를 고려하기 전의 사건에 대한 초기 믿음 또는 확률  

$\frac{P(H) \cdot P(Data \vert H)}{P(Data)}$의 의미는 초기 믿음 또는 확률 $P(H)$에 그런 믿음하에 데이터가 발생할 확률 $P(Data \vert H)$을 곱한 뒤 이 값을 데이터가 나올 확률 $P(Data)$로 나누어 크기를 조정한 것이다. 이를 Normalize라고도 한다. 결과적으로 $P(H) \to P(H \vert Data)$의 의미는 원래 확률 $P(H)$이 데이터를 관측함으로써 어떻게 갱신되었는가? $P(H \vert Data)$를 알 수 있게 된다. 

우도(Likelihood)에 대해 좀 더 설명하면 이전에 살펴보았던 최대 우도 추정법(MLE)에서 $P(data \vert \theta)$가 우도였는데, 이는 모분포와 그에 대한 모수 $\theta$를 가정한 후 Data가 관측될 강도를 의미했다. 베이지안에서 이를 약간 확대해서 해석하면 prior를 가정한 후에 prior조건하에 Data가 관측될 확률이므로 같은 맥락이라 할 수 있다. 

다음 동전던지기 예로 베이지안 관점에서 확률이 어떻게 갱신되는지 살펴보자. 

동전 던지기를 할 때, 느낌상 100번을 던지면 60번은 앞면이 나오는 거 같다고 치자. 그래서 동전이 Unfair하다고 생각한다면, 동전이 Unfair할 확률은 0.6이 된다. 그러면 $P(H) = P(Unfair) = 0.6$이고, Fair할 확률은 $P(Fair) = 0.4$가 된다. 여기서 동전이 Fair하다는 것은 앞면과 뒷면이 나올 확률이 0.5로 같다는 것이다. Unfair할 경우 앞면이 나올 경우는 0.6이라 하자. 

동전을 한 번 던졌을 때 앞면이 나왔을 경우, 동전이 Unfair하다는 믿음이 갱신되는 과정을 살펴보자. 

$$\begin{align}
P(Unfair) &= 0.6 \\ 
P(Data \vert Unfair) &= 0.6 \\ 
P(Data) &= 0.4 \times 0.5 + 0.6 \times 0.6 \\ 
\end{align}$$

$$P(Unfair \vert Data) = \frac{P(Unfair) \cdot P(Data \vert Unfair)}{P(Data)} = 0.6429$$

원래 0.6이었던 $P(H) = P(Unfair) = 0.6$가 Data를 반영한 뒤 갱신되어 $P(H \vert Data) = P(Unfair \vert Data) = 0.6429$로 높아진 것을 확인할 수 있다. 

동전을 두 번 던졌을 때 두 번 모두 앞면이 나왔을 경우, Unfair 믿음이 갱신되는 과정은 다음과 같다. 

$$\begin{align}
P(Unfair) &= 0.6 \\ 
P(Data \vert Unfair) &= (0.6 * 0.6) \\ 
P(Data) &= 0.4 \times (0.5 \times 0.5) + 0.6 \times (0.6 \times 0.6) \\ 
\end{align}$$

$$P(Unfair \vert Data) = \frac{P(Unfair) \cdot P(Data \vert Unfair)}{P(Data)} = 0.6835$$

두 번 모두 앞면이 나온경우 Unfair에 대한 믿음이 더욱 강해지는 것을 확인할 수 있다.     
베이지안 확률에서는 이런 식으로 데이터를 관측하면서 확률을 갱신하는 방식을 사용한다. 

몇가지 예를 더 살펴보자. 다음은 암 진단 오진율과 조건부확률에 관한 문제이다. 

암 진단 키트가 있는데, 성인 중 0.1%가 암에 걸려있다고 하자. 이때 검사는 95%를 발견하고, 오발견은 10%라고 한다. 이때 어떤 사람의 검사 결과가 암이라고 했을 때, 실제로 암에 걸렸을 확률은? 

주어진 정보는 양성을 관측했고(Data), Prior가 성인중 0.1% 확률이라는 점이고, 이 Prior가 참이라는 가정아래 양성을 볼 확률 95%가 Likelihood라는 것이다. 

암을 H, 양성을 +로 표기하면, Tree 형태로 문제를 풀 수 있다. Tree의 시작은 관측사건을 두고, 그 다음에는 Prior와 Prior의 여집합 등으로 Tree를 만든다. Tree의 마지막에는 Prior에 따른 관측사건에 대한 확률을 늘어놓고, 이것이 Likelihood이다. 

<p align="center"><img src="https://github.com/user-attachments/assets/9bdc4e11-e1fe-428e-a960-bcdab283924f" height="" width=""></p>

결국 문제의 상황을 계산하면 다음과 같다. 

$$P(H \vert +) = \frac{P(+ \vert H)P(H)}{P(H)} = \frac{0.001 \times 0.95}{0.001 \times 0.95 + 0.999 \times 0.1} = 0.94\%$$

0.1%에서 키트에서 양성이라고 판단할 경우 0.94%로 갱신된다. 

다른 경우를 살펴보자. 어떤 봉지 안에 A항아리와 B항아리가 들어있고, A항아리와 B항아리가 선택되는 비율은 7:3이다. A항아리에는 흰 공이 2개 검은 공이 8개 있고, B항아리에는 흰 공이 9개 검은 공이 6개 있다. 이때 공 하나를 꺼내봤더니 흰 공이 나왔다고 할 때 어떤 항아리에서 흰 공이 나왔을 확률이 더 큰지 판단해보자. 

흰 공을 봤으므로 흰 공이 Data가 되고, 그때 항아리 A와 B를 각각 Prior로 두고 계산하면 된다. 항아리 A를 기준으로 항아리 A일 확률이 Prior, 항아리 A일 때 흰 공을 볼 확률이 Likelihood가 된다. 

tree를 채워보면 다음과 같다. 

<p align="center"><img src="https://github.com/user-attachments/assets/b55c0794-a44a-443b-8204-0f2919feaba4" height="" width=""></p>

흰 공을 W, 검은 공을 B라 할 때 우리가 비교해야 하는 두 확률은 다음과 같다. 

$$P(A \vert W) = \frac{P(W \vert A)P(A)}{P(W)}$$

$$P(B \vert W) = \frac{P(W \vert B)P(B)}{P(W)}$$

이를 $\frac{P(A \vert W)}{P(B \vert W)}=\frac{P(W \vert A)P(A)}{P(W \vert B)P(B)}$로 계산하여 1보다 큰지 작은지 확인하면 된다. 









