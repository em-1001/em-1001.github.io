---
title:  "[Statistics] Maximum Likelihood Estimation"
excerpt: "Likelihood & Maximum Likelihood Estimation"

categories:
  - Statistics
tags:
  - Statistics
toc: true
toc_sticky: true
last_modified_at: 2025-01-19T08:06:00-05:00
---

> 데이터 사이언티스트 되기 책: https://recipesds.tistory.com/  

# Likelihood

확률(Probability)은 모수 $\theta$가 정해진 상태에서 Data가 목격될 가능성을 의미하고, 우도(Likelihood)는 Data가 관측된 상태에서 특정 확률분포의 모수 $\theta$에 대한 믿음의 강도(strength)를 나타낸다. Likelihood와 확률의 관계는 다음과 같다. 

$$\mathcal{L}(\theta; Observation) = P(Observation; \theta) \cdots (*)$$

Likelihood function은 $\mathcal{L}(\theta \vert x)$로 $x$는 이미 정해진 data이다. $\theta$를 특정 값으로 가정하면, Likelihood function은 함수가 아니라 상수가 되어 특정 모수 $\theta$의 분포에 대한 data $x$의 강도를 나타낸다. 가정한 분포에서 관측한 데이터에 대한 높이 $y$가 강도가 되고, 이 강도가 Likelihood이다. 따라서 강도가 높을수록 해당 데이터를 잘 표현하는 모수라 할 수 있다. 

Likelihood는 $\theta \to \mu, \sigma, p$를 Parameter라 할 때, 다음과 같다. 

$$
\mathcal{L}(\theta \vert x) = 
\begin{cases}
P(X=x \vert \theta) & when \ Discrete \ pmf \\  
f(X=x \vert \theta) & when \ Continuous \ pdf   
\end{cases}
$$

<p align="center"><img src="https://github.com/user-attachments/assets/948993e3-b18d-4e71-a5a7-7d63c289612d"></p>

위 Binomial 분포의 그림을 보면 확률은 확률변수인 event가 $x$축인데 반해, Likelihood는 모수 $p$가 변수가 된다. 특적한 event를 fix하고, 모수가 변함에 따라 관측한 데이터가 얼마나 모수에 잘 맞는지에 대한 강도인 Likelihood의 변화를 나타낸다. 


# Maximum Likelihood Estimation(MLE)

최대우도추정(Maximum Likelihood Estimation)은 관측한 데이터를 통해 Parameter모수를 추정하는 방법이다. 
MLE의 특징은 가장 적절한 분포를 먼저 가정하고, 그 가정된 분포에 대한 가장 적절한 모수 $\theta$를 찾는 것인데, $\theta$를 찾는 근거가 Likelihood이다. 따라서 $\theta$에 대한 Likelihood의 최대값을 찾아내면 그때의 $\theta$가 가장 데이터를 잘 설명하는 분포라 할 수 있다. Likelihood의 최대는 미분해서 0이 되는 지점을 찾으면 된다. $\left( \frac{\partial \mathcal{L}}{\partial \theta} = 0 \right)$ 

MLE를 할 때 모든 Observation은 **i.i.d**이다. **i.i.d**는 Independent and Identical Distribution의 약자로 각 데이터를 뽑을 때, 같은 분포에서 서로 독립인 경우를 말한다. 따라서 **i.i.d**이기 때문에 각각의 Observation에 대해 곱형태의 joint probability를 사용할 수 있다. 

주머니 안에 검은 구슬과 흰색 구슬이 총 100개 있다고 하자. 10번을 뽑아 보았더니 검은 구슬이 7번, 흰색 구슬이 3번 나왔다. 이때 MLE로 검은 구슬은 전체 구슬 중 몇 개가 있을지 추정해보자. 확률 분포는 Binomial로 정하고, 모수 $\theta$는 $p$가 된다. 검은 구슬이 나오는 사건이 $A$, $n=10$, $p$는 검은 구슬이 나올 확률이라 했을 때, $P(A)$는 다음과 같다.

$$P(A) = \left. \binom{n}{k} \cdot p^k q^{n-k} = C \cdot p^k q^{n-k} \right|_{k=7, n=10} = C \cdot p^7 (1-p)^3$$

$C$는 constant이고, 우리가 추정하는 모수 $\hat{p}$는 아래처럼 Likelihood $P(A)$를 최대화하는 $p$를 구하면 된다. 

$$\hat{p} = arg \max_p(C \cdot p^7 (1-p)^3)$$

Linear function에 log를 취해보면 monotonically increasing한다. 이는 원래 함수의 최대값을 갖는 점과 log를 취한 함수의 최댓값을 갖는 점이 같다는 것으로, Binomial Likelihood에 log를 씌워도 마찬가지 이다. 

<p align="center"><img src="https://github.com/user-attachments/assets/2bb7a43c-49bf-4120-82fb-acce114a2273"></p>

따라서 log를 씌운 형태에서 미분을 하여 최댓값을 구할 수 있다. 이에 따라 추정 값 $\hat{p}$를 구해보면 다음과 같다. 

$$\begin{align}
\hat{p} &= \ arg \max_p(C \cdot p^7 (1-p)^3) \\  
&= \to arg \max_p(\log (C \cdot p^7 (1-p)^3)) = arg \max_p(\log(C) + 7 \cdot \log(p) + 3 \cdot \log(1 - p))
\end{align}$$

$p$에 대해 미분하여 0이 되는 지점을 찾으면 되므로 

$$\frac{d(\log(C) + 7 \cdot \log(p) + 3 \cdot \log(1 - p))}{dp} = 0$$ 

$\frac{7}{p} - \frac{3}{1-p} = 0$을 풀면 된다. 

다른 예로 Gaussian Distribution의 모수 $\mu$를 MLE로 추정해보자. Gaussian Distribution의 pdf는 다음과 같다. 

$$P(x; \mu, \sigma) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{\left( -\frac{(x-\mu)^2}{2\sigma^2} \right)}$$

Gaussian분포에서 9, 10, 11을 관측했다고 하자. 이 경우 어떤 모수를 갖는 가우시안 분포가 관측한 데이터를 가장 잘 설명하는지 MLE로 추정한다. MLE로 모수를 추정하기 위한 joint probability를 표현하면 다음과 같다. 

$$\begin{align}
P(9,10,11;\mu, \sigma) &= \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left( -\frac{(9-\mu)^2}{2\sigma^2} \right) \\ 
&\times \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left( -\frac{(10-\mu)^2}{2\sigma^2} \right) \\ 
&\times \frac{1}{\sqrt{2\pi\sigma^2}} \exp \left( -\frac{(11-\mu)^2}{2\sigma^2} \right)
\end{align}$$

i.i.d를 만족하기 때문에 위와 같이 곱형태로 나타낼 수 있다. 여기에 log를 씌으면 다음과 같다. 

$$\begin{align}
\ln(P(x; \mu, \sigma)) &= \ln \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right) - \frac{(9-\mu)^2}{2\sigma^2} \\  
&+ \ln \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right) - \frac{(10-\mu)^2}{2\sigma^2} \\  
&+ \ln \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right) - \frac{(11-\mu)^2}{2\sigma^2} 
&= 3 \cdot \ln \left( \frac{1}{\sqrt{2\pi\sigma^2}} \right) - \frac{1}{2\sigma^2}\lbrack (9-\mu)^2 + (10-\mu)^2 + (11-\mu)^2 \rbrack
\end{align}$$

$\mu$에 대해 미분하여 max를 찾으면 다음과 같다. 

$$\frac{\partial \ln(P(x; \mu, \sigma))}{\partial \mu} = \frac{1}{\sigma^2} \lbrack 9 + 10 + 11 -3\mu \rbrack = 0$$

$$\mu = \frac{9 + 10 + 11}{3} = 10$$







