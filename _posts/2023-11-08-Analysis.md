---
title:  "[Statistics] Analysis"
excerpt: Analysis

categories:
  - Statistics
tags:
  - Statistics
toc: true
toc_sticky: true
last_modified_at: 2025-01-19T08:06:00-05:00
---

> 데이터 사이언티스트 되기 책: https://recipesds.tistory.com/

# Analysis

<p align="center"><img src="https://github.com/user-attachments/assets/9bfe042e-ab06-4b33-bb49-51605815032b" height="" width=""></p>

이제부턴 분석에 대해 다룰 것이다. 검정에서 봐왔던 $t$-test도 사실 분석의 일종이라 할 수 있다. 하지만 2개 집단 차이를 볼 때 차이 분석이라 부르지 않고 보통 $t$ 검정이라 한다. 이제 다룰 ANOVA는 분석이라 하는데 $t$ 검정이라 불리는 이유는 검정을 하기 전에 표본 분석을 통한 통계량을 구하기 위해 적당한 Grouping이나 데이터 변환등을 동원해서 데이터 처리를 하는 단계가 있는데, 차이 분석의 경우는 표본을 구하기만 하면 곧바로 검정이 가능하므로 특별하게 분석이라 부르지 않고 그냥 차이 검정 또는 $t$ 검정이라 부른다. 분석의 예를 들면, ANOVA는 분산의 아이디어로부터 표본(원시 (Raw) 데이터)을 분산의 형태로 변환해서, F검정을 하고, 교차분석은 교차표라는 형태로 데이터를 Agrregation 한 후에 카이제곱 검정을 한다. 

# ANOVA

ANOVA(Analysis of Variance)는 분산분석으로 3개 이상의 집단 간 평균의 차이를 검정할 때 사용한다. 평균의 차이를 검정하는데 이름이 분산분석인 이유는 분산의 성질과 원리를 이용한 평균차이 분석이기 때문이다. ANOVA는 평균을 직접 비교하지 않고, 집단내의 분산과 각 집단 간의 평균의 분산을 이용해 평균이 다른지 확인하는 방법이다. 

<p align="center"><img src="https://github.com/user-attachments/assets/96b8aa71-4d62-4f2d-89ca-115a656d6ed3" height="" width=""></p>

3개의 집단이 있다고 할 때, 위 그림을 통해 알 수 있듯이 집단 평균 간의 분산이 크고, 집단 내의 분산이 작으면 평균이 서로 확실히 다르다는 것을 알 수 있다. 위 그림에서는 3번 케이스를 제외하고는 평균이 다르다고 단정 지을 수 없다. ANOVA의 기준은 집단간 평균의 분산이 커지고, 집단 내 분산이 작아지는 3번의 경우를 기준으로 찾아낼 수 있고, 이러한 경향이 커질수록 통계량 값은 커진다. 따라서 평균 제곱 간의 비를 (집단 간 평균의 분산 / 집단 내 분산) 으로 정의할 수 있다. 이때의 검정 통계량 $F$는 $F$ 분포를 따르고, 이 차이가 통계적으로 유의한 지를 분석해서 평균이 모두 같다는 귀무가설을 검증하면 된다. 

분산 자체는 $\chi^2$ 카이스퀘어 분포를 따르는데, 분자 분모가 모두 카이스퀘어 분포를 따르는 경우에 이런 비율이 따르는 분포는 $F$ 분포를 따른다. 따라서 ANOVA에서는 $F$ 분포를 사용한다. 우리가 이용하는 F분포는 Null Hypothesis가 집단간 평균이 같을 경우의 F값(통계량)의 분포이다. 만약 F분포에서 관측된 F값(통계량)으로 p값을 계산해 보았는데 p값이 너무 작은 경우에는 평균이 서로 같은 환경에서 관측하기 어려운 것이므로 집단 중에 최소한 1개는 평균이 다르다라고 결론을 낼 수 있다. 

통계량은 앞서 (집단 간 평균의 분산 / 집단 내 분산)를 (Between Mean Variance/ Within Variance)로 표현한다. 이 의미는 Between Mean Variance가 Within Variance에 비해 크면 최소한 1개 그룹은 차이가 난다고 할 수 있다. 그러므로 $F = \frac{Mean_{Between}}{Mean_{Within}}$ 을 (설명된 분산 / 설명되지 않은 분산) 으로 표기하는데, 설명된 분산이란 이미 계산할 값들이 정해지는 경우이고, 설명되지 않은 분산이란 계산 시 경우에 따라 Random 하게 다르게 정의하고, 자유도는 Between의 경우 k group-1, Within의 경우 n-k (sample-group)이 된다. 두 자유도의 합은 n-1이 되며, 이유는 k 그룹으로 mean을 구했으니 k-1 자유도가 되고, Within의 경우 전체 n 개에서 k개 그룹의 mean을 이미 구했으므로 n-k가 된다. 

예를 들어서 남학생, 여학생, 외계인 학생의 발 길이에 대한 데이터가 있다고 하자. 

boy = [27.3, 28.5, 29.7]  
girl = [23.5, 24.2, 22.2, 25.7]   
alien = [19.2, 18.6, 17.1]   

이 데이터를 기반으로 각 집단의 평균에 대한 분산(Between), 각 집단 내 평균에 대한 분산(Within)을 구하면 다음과 같다. 

<p align="center"><img src="https://github.com/user-attachments/assets/5ebb0554-25b1-4b89-91ac-f84731b675d9" height="" width=""></p>

$$F = \frac{⓵/dof_{between}}{⓶/dof_{within}} = \frac{156.66/2}{11.6/7} = 47.268$$

결국 집단별 표본평균의 분산은 중심극한정리에 의해 $\sigma_x = \frac{\sigma}{\sqrt{n}}$ 이므로, $\sigma^2 = n\sigma_x^2$이 되고, 표본분산을 이용해 추정한 모분산은 $\sigma^2 = ns_x^2$ 가 되므로, ⓵은 각각의 집단의 표본평균의 분산을 각각 구해서 더한 것 즉, $3 \times (28.5-23.6)^2 + 4 \times (23.9 - 23.6)^2 + 3 \times (18.3 - 23.6)^2$이고, 결국 집단 수에 대한 자유도로 평균을 낸 값이다. ⓶는 집단내 편차들의 전체 제곱합으로, 단순하게 각 집단 내의 모든 편차 제곱을 다 더해서 자유도로 평균낸 값이다. 

5% 유의수준으로 검정해보면, 유의 수준 5% 일 때의 F값을 F테이블을 이용해서 구해보면 4.74이다. 

<p align="center"><img src="https://github.com/user-attachments/assets/de65247e-959d-455e-a185-30b568178028" height="" width=""></p>

<p align="center"><img src="https://github.com/user-attachments/assets/426d8d82-f0dc-408e-ae5e-e40cff335881" height="" width=""></p>

결과적으로 p value가 매우 작으므로 귀무가설은 기각되어 3개의 그룹은 차이가 있다고 결론지을 수 있다. 

파이썬을 이용하면 다음과 같다. 

```py
from scipy import stats
 
boy = [27.3, 28.5, 29.7]
girl = [23.5, 24.2, 22.2, 25.7]
alien = [19.2, 18.6, 17.1] 
 
stats.f_oneway(boy, girl, alien)

> F_onewayResult(statistic=47.26810344827576, pvalue=8.603395069970194e-05)
```

여기서 one way는 일원분산분석이라고 해서 one way AVONVA라 한다. 이 의미는 우리가 비교하려는 요인의 개수가 1개라는 의미이다. 
그룹(집단)을 군 또는 수준 이라고도 하고, 요인은 각 그룹(집단)을 구분짓게 하는 것인데, 실험요인/인자/독립변수(Factor) 라고도 한다. 
발길이에 대한 예를 다시 한번 살펴보면 group(boy, girl, alien)이 독립변수, 발길이가 종속변수. 즉, group에 따라 발길이가가 달라지는지 1개의 독립변수와 1개의 종속변수를 검정한 것이라고 할 수 있다.

다른 예를 들어 한 마케팅연구에서 30명의 표본을 선정한 후 이들을 임의로 세 가지 형태의 콜라 광고 중 하나를 시청하게 하였다. 1시간 동안 시청하게 한 후, 광고에 반응하는 것(구매욕구)을 측정하여 세 가지 광고의 차이가 있는지 알고자 할때, 

측정값 : 구매욕구 (종속변수)  
요인 : 광고 (독립변수)  
수준 : 3가지 광고   

가 된다. 광고에 따라 구매욕구가 달라지는가를 연구할 떄, one way ANOVA를 한다고 할 수 있다. 
여기에 광고에 따라 그리고, 남/여에 따라 어떻게 되는지 확인하게 되면 two way ANOVA가 된다. 

<p align="center"><img src="https://github.com/user-attachments/assets/155ae5df-978e-4d3a-9207-c4dd832eb6c9" height="" width=""></p>

3개 이상의 집단끼리 차이를 분석할 때, 2개씩 짝이어서 t 검정을 하지 않고 ANOVA를 쓰는 이유는, 예를 들어 3개 그룹을 비교할 때는 3가지 짝지움을 할 수 있다. 이때, 1개의 짝지움에 대해 t Test를 하는 경우에는 α=5%로 보았을 때에는 잘못 판단하지 않을 확률이 95%이다. 이제 3번을 연속해서 검정하게 되는데, 유의하지 않을 확률  95%, 유의할 확률 5%의 동전을 던진다고 할 때, 3번 연속해서 동전을 던진 후에 한 번도 유의하지 않을 확률은 95% x 95% x 95%이다. 따라서  최소한 한 번이라도 유의할 확률은 1 - 95% x 95% x 95%가 된다. 이렇게 되면 원래 α는 5%로 시작했지만 3번 연속 검정을 하게 되면 1 - 95% x 95% x 95% = 0.142625가 되어 약 14.2%정도로 α가 커진다. 이렇게 되면 원래 5%로 판단하려고 했던 처음 의도와 다르게 14.2%를 기준으로 유의성을 판단하는 것과 같은 효과가 된다. 이를 일반화 하면, 전체 그룹에서 2개를 뽑는 경우만큼 t test를 하고, 신뢰도는 1-α이므로 $1 - (1 - \alpha)^{_{n}C _{2}}$ 가 된다. 이렇게 되었을 때 유의확률α가 커지니까 False Positive 오류 (Type I Error)를 범할 확률이 커지게 된다. 

추가적으로 2개 그룹의 평균을 비교할 때 t test 대신 ANOVA를 써도 된다. 등분산의 2개 집단에 대해 Independent two Samples t-test결과와 ANOVA결과는 p value가 똑같이 나온다. 게다가 두 분석의 통계량은 제곱 관계로서, t값을 제곱하면 F값이 나온다. 

ANOVA는 분산의 동질성(모분포에 대해)이 매우 중요하다. 이 분산의 동질성 가정을 만족하지 못하는 경우에는, Welch 검정을 하게된다. 


## Post Hoc

Post Hoc(사후분석)은 ANOVA에서 유의(Significant)하다는 검정 결과가 나왔을 때, 집단 중 어느 집단이 다른 것인가를 찾아내는 것이다. 
ANOVA의 Alternative Hypothesis는 최소한 1개의 집단은 평균이 다르다이므로 어느 것이 다른지를 찾아야 한다. 앞서 말했듯이 t test를 $_{n} C _{2}$번 해서 찾아내는 것은 $1 - (1 - \alpha)^{ _{n}C _{2}}$ 로 유의수준이 커지므로 Type I Error가 늘어난다. 

사후분석을 위한 방법에는 Fisher's LSD(피셔의 LSD), Tukey' HSD 투키의 HSD), Bonferroni correction (봉페로니교정), Duncan (던칸의 방법), Scheffe (셰페의 방법), Games Howell (게임즈 하웰) 등이 있고, 이런 분석들을 통틀어 Post Hoc이라 한다. 이러한 사후분석들은 모두 등분산을 가정하고 차이는 다음과 같다. 

1. Fisher's LSD: 집단을 짝지어 t test를 아무 보정 없이 하는 방법으로 좋은 방법이 아니다.
2. Tuckey' HSD: 비교 집단간 표본크기가 동일한 경우 사용하고, t분포를 사용한다.
3. Bonferroni: t검정을 짝지어서 검정한 후 유의수준 $\alpha$를 5%로 보정한다. 보정된 유의수준은 FWE라 부른다.
4. Duncan: Duncan은 작은 차이에도 차이가 난다고 결과를 낸다. 집단 간 차이가 꼭 드러나야 하는 경우 사용하는 것이 좋고, 사회과학 등에서 설문을 할 때 많이 사용한다.
5. Sheffe: 큰 차이가 나야 차이가 난다고 결과를 낸다. F분포를 활용해 검정한다.

위는 일반적인 ANOVA의 Post Hoc이고, 등분산이 아닌 경우 Welch 검정을 하는데 이 경우에는 Games Howell를 사용한다. Games Howell는 Welch의 방법으로 t분포의 자유도를 바꿔서 검정한다. 

만약 ANOVA에서 유의하다고 결과가 나왔는데, Post Hoc에서 유의하지 않다고 나올 수도 있다. 즉, ANOVA에선 차이가 있다고 해놓고 막상 어떤 집단이 다른지 모르는 경우엔 집단 간 차이가 유의한 것으로만 단순 해석하는 것이 합리적이다. 

앞서 발길이 예시로 실제 검정을 해보면 다음과 같다. 

```py
boy = [27.3, 28.5, 29.7]
girl = [23.5, 24.2, 22.2, 25.7]
alien = [19.2, 18.6, 17.1]
```

1.정규성 검정(Shapiro-Wilk)

```py
from scipy.stats import shapiro
 
boy = [27.3, 28.5, 29.7]
girl = [23.5, 24.2, 22.2, 25.7]
alien = [19.2, 18.6, 17.1] 
 
print(shapiro(boy))
print(shapiro(girl))
print(shapiro(alien))
 
>
ShapiroResult(statistic=1.0, pvalue=0.9999986886978149)
ShapiroResult(statistic=0.9968306422233582, pvalue=0.9891670346260071)
ShapiroResult(statistic=0.9423076510429382, pvalue=0.5367357134819031)
```

세 집단 모두 정규성 검정을 통과한다. 사실 표본이 작기 때문에 큰 의미는 없고, 모집단이 정규성을 띄므로 표본의 평균도 정규적이라고 가정할 수 있다. 

2.등분산성 검정(Levene, Bartlett)

```py
from scipy.stats import levene, bartlett
 
print(levene(boy, girl, alien))
print(bartlett(boy, girl, alien))
 
>
LeveneResult(statistic=0.19816176470588293, pvalue=0.8246838520550716)
BartlettResult(statistic=0.19083867589274103, pvalue=0.9089916798322615)
```

Levene과 Bartlett에서 모두 등분산 검정을 통과하므로 3개의 집단이 모두 모분산이 동질하다고 할 수 있다. 

3.One way ANOVA

```py
from scipy.stats import f_oneway
 
f_oneway(boy, girl, alien)
 
>
F_onewayResult(statistic=47.26810344827576, pvalue=8.603395069970194e-05)
```

유의하다는 결과가 나오므로 세 집단에 차이가 있다.   

이제 어느 집단이 다른지 확인할 수 있도록 Post Hoc을 해보면 표본의 크기가 서로 다르므로 Bonferroni를 사용한다. 
Bonferroni를 하기 전에 데이터의 모양새가 값과 그룹의 종류에 대한 데이터를 순서를 맞추어 넣으면 pandas dataframe로 다음과 같다. 

```py
import pandas as pd
 
lst_value = boy + girl + alien
lst_group = ["boy" for i in range(len(boy))] + ["girl" for i in range(len(girl))] + ["alien" for i in range(len(alien))]
df_total = pd.DataFrame({'Group':lst_group, 'Value':lst_value}).reset_index(drop=True)
print(df_total)
 
>
    Group  Value
0    boy   27.3
1    boy   28.5
2    boy   29.7
3   girl   23.5
4   girl   24.2
5   girl   22.2
6   girl   25.7
7  alien   19.2
8  alien   18.6
9  alien   17.1
```

이렇게 데이터를 만들어야 Bonfrroni를 할 수 있다. 

```py
from statsmodels.sandbox.stats.multicomp import MultiComparison
from scipy.stats import ttest_ind
 
comp = MultiComparison(df_total['Value'], df_total['Group'])
ret = comp.allpairtest(scipy.stats.ttest_ind, method='bonf')
print(ret[0])
 
>
Test Multiple Comparison ttest_ind 
FWER=0.05 method=bonf
==============================================
group1 group2   stat    pval  pval_corr reject
----------------------------------------------
 alien    boy -10.9355 0.0004    0.0012   True
 alien   girl  -5.5521 0.0026    0.0078   True
   boy   girl   4.4257 0.0069    0.0206   True
----------------------------------------------
```

pval_corr이 집단의 개수로 곱해진 보정된 p value이고, 모두 유의하다는 것을 알 수 있다. 따라서 서로 모두 차이가 있다. 


## RMANOVA

특정 시점을 기준으로 그 시점의 전후 2개 집단의 차이를 검정할 때 Paired t Test를 했었다. Paired t Test는 변화 한 번만 봐서 집단이 2개인 경우인데,  RMANOVA(Repeated Measured ANOVA)는 변화를 여러번 보는 것이다. 따라서 변화에 대해 비교 시점이 여러 개가 되고, 비교하는 집단이 여러 개가 된다. 

Paired t Test때와 비슷한 예시로 어떤 정신과 의사가 환자들을 상대로 스트레스 호르몬인 코르티솔을 줄이기 위해  코끼리를 타고 바흐의 음악을 계속 듣게 했다고 하자. 현재 코르티솔을 측정하고, 1주일 후에 측정하고, 2주일 후에 측정했다고 하면 세 시점이 된다. 

<p align="center"><img src="https://github.com/user-attachments/assets/4531b845-bc8c-4182-a50d-806169f6a88a" height="" width=""></p>

산수적인 계산은 ANOVA와 동일하므로 파이썬으로 분석을 해보자. Null Hypothesis는 "세 시점에 변화가 없다."이고, Alternative Hypothesis는 "적어도 한 시점에서는 변화가 있다."이다. 파이썬으로 RMANOVA를 하기 위해서 statsmodel의 AnovaRM 모듈을 이용한다. 

AnovaRM를 사용하려면 각 시점에 대한 데이터를 한 개의 컬럼에 모두 넣은 후 Subject와 시점을 붙여 넣어야 한다. 

<p align="center"><img src="https://github.com/user-attachments/assets/20273b54-4b56-462d-bf05-9ee2695cdbf1" height="" width=""></p>

```py
from statsmodels.stats.anova import AnovaRM
 
print(AnovaRM(data=df_data, depvar='value', subject='id', within=['viewPoint']).fit())
 
>
 Anova
                Anova
=======================================
          F Value Num DF  Den DF Pr > F
---------------------------------------
viewPoint 58.8882 2.0000 38.0000 0.0000
```

이런 식으로 AnovaRM 분석을 할 수 있고, F검정 결과까지 한 번에 볼 수 있다. F Value가 58.8882로 매우 큰 통계량이 나왔고 p value(Pr>F)는 매우 작다. 따라서 F 검정의 Null Hypothesis를 기각하여 3개의 시점 중에 차이가 나는 다른 것이 적어도 하나 있다고 할 수 있다. 

이제 Null Hypothesis가 기각되었으니 어떤 시점이 다른 시점과 다른지 알아야 한다. RMANOVA를 할 때는 전제조건이 있는데, 정규성 전제와 구형성전제가 있다. 정규성 전제는 기존에 했던 것과 동일하고 구형성(Sphericity)은 다음과 같다. 

<p align="center"><img src="https://github.com/user-attachments/assets/b6394234-cdcb-4879-8b62-4f91b4381f4a" height="" width=""></p>

ANOVA의 등분산성에 대응되어서 RMANOVA는 차이의 분산들이 등분산성을 가져야 한다는 의미이다. 이를 pingouin 패키지를 통해 테스트할 수 있고, Mauchy's Test of Sphericity라 한다. 

```py
import pingouin as pg
pg.sphericity(data=df_data, dv='value', within='viewPoint', subject='id')
 
>
SpherResults(spher=False, W=0.6111256376806817, chi2=8.864148863341935, dof=2, pval=0.011889799495965416)
```

결과를 확인해보니 구형성을 만족하지 못한다. 이럴 때 t test에서 등분산이 아닐 때  Welch's Testing을 위해서 correction을 줄 수 있던 것과 같이 할 수 있다. 

```py
import pingouin as pg
pg.rm_anova(dv='value', within='viewPoint', subject='id', data=df_data, correction=True)
 
> 
Source    ddof1 ddof2  F            p-unc	...
viewPoint  2     38    58.888199    2.282217e-12 ...
```

이런 경우에 correction을 True로 주면 구형성을 만족하지 못하는 경우에도, Greenhouse-Geisser correction과 Huynh-Feldt correction을 적용하여  결과를 낸다. correction을 한 결과의 F값은 58.888199이고, p value는 2.282217e-12로 귀무가설이 기각될 수 있다. correction=False로 주면 F통계량이 58.8882, p value는 거의 0. 으로 아까의 결과와 동일한 결과를 낸다. 

이제 Post Hoc을 할 차례다. RMANOVA도 Post Hoc이 있는데, Benjamini/Hochberg FDR correction이라는 방법이다. 각 시점별로 pair를 만들어서 t Testing을 할 때 FWER를 보정해서 결과를 알려준다. 아이디어는 Bonferroni와 같고 이 방법은 pingouin에서 제공한다. 

```py
import pingouin as pg
print(pingouin.__version__)
posthoc = pg.pairwise_ttests(dv='value', within='viewPoint', subject='id', data=df_data)
print(posthoc)
 
>
A             B            Paired T         dof alternative p-unc
1 week later  2weeks later  TRUE  4.152317  19  two-sided   5.41E-04
1 week later  present TRUE  TRUE  -6.997791 19  two-sided   1.15E-06
2 weeks later present TRUE  TRUE  -9.38871  19  two-sided   1.44E-08
```

결과를 확인하면 다 다른다는 것을 알 수 있다. 결국 코르티솔은 계속 줄어서 코끼리를 타고 바흐를 듣는 것은 개선의 효과가 있었다고 할 수 있다. 


# Cross tabulation

이번엔 교차분석에 대해 알아볼 것이다. cross table(contingency table)은 빈도에 관련한 교차표이다. 범주형 자료에 대해서 빈도를 분석한다고 생각할 수 있다. 다음과 같이 교차집계표를 만들 수 있다면, 이미 검정에서 살펴본 독립성(연관성), 동질성 검정이 가능하다. 

<p align="center"><img src="https://github.com/user-attachments/assets/20e1529f-24a1-4837-a374-dac6a5b6dc28" height="" width=""></p>

이런 식의 데이터가 있다고 할 때, cross table은 두 개의 컬럼을 교차하여 만든다. 

<p align="center"><img src="https://github.com/user-attachments/assets/89f80173-e96d-4e1d-9880-36dd010d960f" height="" width=""></p>

cross table은 Grouping and Agggregation이다. row와 column을 Grouping을 한 후에 그에 대한 집계를 하는 것이다. 따라서 사과, 수박, 오렌지가 아무리 많이 나와도 이 세 가지로 Grouping이 가능하고, 출하일은 9월 1일, 9월 2일, 9월 3일로 모두 Grouping 해서 몰아넣을 수 있다. 

cross tabulation은 pandas의 crosstab을 이용해 만들 수 있다. 

```py
pd.crosstab(df_data['과일'], df_data['출하일'])
```

이 결과는 과일의 unique value들 (Grouping)과 출하일의 unique value만(Grouping)을 index와 column으로 만들어서 그 수를 count(Aggregation)하는 결과이다. 

raw data가 pandas의 Dataframe일 때, pandas의 pivot으로도 만들 수 있다. 

```py
pd.pivot_table(df_data, index='과일', columns='출하일', aggfunc='size')
```

이렇게 하면 똑같은 결과가 나온다. pivot은 pandas dataframe을 통째로 데이터로 넣은 다음에 그중에 index와 column이 무엇인지 정해주면 된다. pivot을 이용해서 집계를 할 수 있는데, 과일별 - 출하일에 대해서 당도의 (각각의 Grouping) 평균(Aggregation)을 보고 싶다고 한다면 데이터 개수를 count를 하는 대신에, count자리에 다른 column값을 넣을 수 있다. 

```py
pd.pivot_table(df_data, index='과일', columns='출하일', values='당도')
```

<p align="center"><img src="https://github.com/user-attachments/assets/2d1acfe2-34fb-478b-b266-03daebe949d1" height="" width=""></p>


## $\chi^2$ Testing, Cramer V

교차분석은 관심 있는 표본으로부터 Categorical(명목형) 데이터에 대하여 pivot table이나 cross table (contingency table)을 만들어 행과 열을 교차하여 교차빈도집계표를 구한 후에 카이스퀘어 검정을 이용하여 동질성, 독립성을 검정하는 것이다. 

예시를 통해 분석, 검정, 연관도 확인까지 해보자. 아래와 같인 데이터가 있다고 하자. 

<p align="center"><img src="https://github.com/user-attachments/assets/3049d792-2436-48f7-b635-ee30ca55c1c7" height="" width=""></p>

최종적으로 카이스퀘어 검정을 하니까 가설을 설정하면 다음과 같다.  

$H_0$: 두 변수는 독립이다.   
$H_1$: 두 변수는 독립이 아니다. (연관이 있다.)  

일단 첫 번째로 거주지에 따른 대학 진학에 차이가 있는지 확인해보자. 

```py
df_cross_table = pd.crosstab(df_data['거주지'], df_data['대학진학'])
 
df_cross_table = pd.pivot_table(df_data, index='거주지', columns='대학진학', aggfunc="size")
 
>
대학진학  미진학   진학
거주지           
광역시    90  122
시구군    42   50
시군구    16   30
특별시   110  150
```

이렇게 만들어진 교차집계표로 바로 카이스퀘어 검정을 할 수 있다. 교차표의 각 row가 각각 list로 들어가야 하니까 각 row에 대한 list를 만들어 `[[90, 122],[42, 50], [16, 30], [110, 150]]`의 형태가 되도록 넣어주면 된다. 

```py
from scipy.stats import chi2_contingency
rows = [row.to_list() for i, row in df_cross_table.iterrows()]
chi2_contingency(rows, correction=False)
 
>
(1.490709512981629,
 0.6844162240071692,
 3,
 array([[ 89.66557377, 122.33442623],
        [ 38.91147541,  53.08852459],
        [ 19.4557377 ,  26.5442623 ],
        [109.96721311, 150.03278689]]))
```

p value가 0.68이므로 거주지에 따른 대학진학결과가 독립이라 할 수 있다. 결과로 나오는 첫 번째는 카이제곱 통계량, 두 번째는 p value, 세 번째는 자유도, 마지막은 서로 독립일 때의 expected 빈도의 row list이다. 

이번에는 부모의 학력이 대학 진학에 영향을 끼치는지 확인해보자. 

```py
df_cross_table = pd.crosstab(df_data['부모학력'], df_data['대학진학'])
>
대학진학  미진학   진학
부모학력          
고졸    112  126
대졸     70  140
대학원졸   76   86
 
 
rows = [row.to_list() for i, row in df_cross_table.iterrows()]
chi2_contingency(rows, correction=False)
>
(10.539167067134844,
 0.005145753160303171,
 2,
 array([[100.66229508, 137.33770492],
        [ 88.81967213, 121.18032787],
        [ 68.51803279,  93.48196721]]))
```

부모의 학력과 진학은 독립이 아님을 확인할 수 있다. 서로 연관이 있으므로 얼마나 연관이 있는지 알아봐야 하는데, 명목형 변수-명목형 변수(Categorical - Categorical)를 분석하는 경우에는 크래머V (Cramer V)라는 것을 이용해서 얼마나 서로 연관되어 있는지 알 수 있다. 명목형 변수는 대상에 대해 측정하면 대상을 일정한 범주에 속하게 하며 대상에 이름이 붙여지지만 각 범주 간에 순위는 없는 항목을 말한다. 예를 들어 성별(남, 여), 인종(황인종, 흑인종, 백인종), 혈액형(AB, A, B, O), 검사결과여부(양성, 음성) 등이 있다. 

$$CramerV = \sqrt{\frac{\chi_{stat}^2 \div n}{min(r-1, c-1)}}$$

위 식을 Cramer V - 연관 계수라 한다. 카이스퀘어의 결과값은 고정된 같은 확률에 대해 전체 표본의 개수가 크면 큰 값이 나오는 경향이 있기 때문에 이를 없애기 위해 $n$으로 나눈다. 그리고 이 나눈 값의 최댓값이 $min(r-1, c-1)$이 되는데 이 값으로 다시 나누어 0~1사이의 값으로 정규화 한다. 이때 이 최댓값을 Cramer의 phi $\phi$라 한다. 

쉽게 말해 카이스퀘어값과 관련되어 있으니까 서로 독립일 때 기대했던 값과 차이가 많이 날 수록 더 연관되어 있다고 볼 수 있다. 결과를 계산해보면, 

```py
import numpy as np
 
x2 = chi2_contingency(rows, correction=False)[0]
n = np.sum(rows)
minDimension = min(np.array(rows).shape)-1
 
V = np.sqrt((x2/n) / minDimension)
 
print(V)
 
>
0.13144323132393237
```

 0.131 정도로 서로 영향을 끼치긴 하는데 그렇게 큰 영향은 아니다. 이 정도는 통계적으로 유의하고, 약한 연관관계를 갖는다고 할 수 있다. 보통 0.6이상이 되면 강한 연관관계가 있다고 한다. 

 










