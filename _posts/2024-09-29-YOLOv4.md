---
title:  "YOLOv4"
excerpt: "YOLOv4 from scratch"

categories:
  - Computer Vision
tags:
  - AI
  - Computer Vision
  - Project
last_modified_at: 2024-09-29T08:06:00-05:00
---

<img src="/assets/images/yolov4/cat0_1.png">&#160;&#160;&#160;&#160;<img src="/assets/images/yolov4/cat1_1.png"> 

### Configuration  
```ini
DATASET = PASCAL_VOC
ANCHORS = [
    [(0.28, 0.22), (0.38, 0.48), (0.9, 0.78)],
    [(0.07, 0.15), (0.15, 0.11), (0.14, 0.29)],
    [(0.02, 0.03), (0.04, 0.07), (0.08, 0.06)],
] 

BATCH_SIZE = 32
OPTIMIZER = Adam
NUM_EPOCHS = 100
CONF_THRESHOLD = 0.05
MAP_IOU_THRESH = 0.5
NMS_IOU_THRESH = 0.45
WEIGHT_DECAY = 1e-4

# 0 ~ 30 epoch                # Cosine Annealing                            

LEARNING_RATE = 0.0001        LEARNING_RATE = 0.0001        
                              T_max = 100
# 30 ~ 50 epoch               

LEARNING_RATE = 0.00005       

# 50 ~  epoch                

LEARNING_RATE = 0.00001      

```

### NMS(Non-maximum Suppression)

|Detection|320 x 320|416 x 416|512 x 512|
|--|--|--|--|
|CSP|?|43.5|?|
|CSP + GIoU|?|?|?|
|CSP + DIoU|?|?|?|
|CSP + CIoU|?|46.4|?|
|CSP + SIoU|?|46.2|?|
|CSP + CIoU + CA|?|?|?|
|CSP + CIoU + CA + M|?|?|?|

### DIoU-NMS

|Detection|320 x 320|416 x 416|512 x 512|
|--|--|--|--|
|CSP + CIoU|?|46.4|?|
|CSP + CIoU + CA|?|?|?| 


# YOLOv3

## Bounding Box

<p align="center"><img src="/assets/images/yolov4/bbox.png"></p>

YOLOv2 ë¶€í„° Anchor box(prior box)ë¥¼ ë¯¸ë¦¬ ì„¤ì •í•˜ì—¬ ìµœì¢… bounding box ì˜ˆì¸¡ì— í™œìš©í•œë‹¤. ìœ„ ê·¸ë¦¼ì—ì„œëŠ” $b_x, b_y, b_w, b_h$ê°€ ìµœì¢…ì ìœ¼ë¡œ ì˜ˆì¸¡í•˜ê³ ì í•˜ëŠ” bounding boxì´ë‹¤. ê²€ì€ ì ì„ ì€ ì‚¬ì „ì— ì„¤ì •ëœ Anchor boxë¡œ ì´ Anchor boxë¥¼ ì¡°ì •í•˜ì—¬ íŒŒë€ìƒ‰ì˜ bounding boxë¥¼ ì˜ˆì¸¡í•˜ë„ë¡ í•œë‹¤.  

ëª¨ë¸ì€ ì§ì ‘ì ìœ¼ë¡œ $b_x, b_y, b_w, b_h$ ë¥¼ ì˜ˆì¸¡í•˜ì§€ ì•Šê³  $t_x, t_y, t_w, t_h$ë¥¼ ì˜ˆì¸¡í•˜ê²Œ ëœë‹¤.
ë²”ìœ„ì œí•œì´ ì—†ëŠ” $t_x, t_y$ ì— sigmoid($\sigma$)ë¥¼ ì ìš©í•´ì£¼ì–´ 0ê³¼ 1ì‚¬ì˜ ê°’ìœ¼ë¡œ ë§Œë“¤ì–´ì£¼ê³ , ì´ë¥¼ í†µí•´ bboxì˜ ì¤‘ì‹¬ ì¢Œí‘œê°€ 1ì˜ í¬ê¸°ë¥¼ ê°–ëŠ” í˜„ì¬ cellì„ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ í•´ì¤€ë‹¤. ì—¬ê¸°ì— offsetì¸ $c_x, c_y$ë¥¼ ë”í•´ì£¼ë©´ ìµœì¢…ì ì¸ bboxì˜ ì¤‘ì‹¬ ì¢Œí‘œë¥¼ ì–»ê²Œ ëœë‹¤.

$b_w, b_h$ì˜ ê²½ìš° ë¯¸ë¦¬ ì •í•´ë‘” Anchor boxì˜ ë„ˆë¹„ì™€ ë†’ì´ë¥¼ ì–¼ë§Œí¼ì˜ ë¹„ìœ¨ë¡œ ì¡°ì ˆí•  ì§€ë¥¼ Anchorì™€ $t_w, t_h$ì— ëŒ€í•œ log scaleì„ ì´ìš©í•´ êµ¬í•œë‹¤.

YOLOv2ì—ì„œëŠ” bboxë¥¼ ì˜ˆì¸¡í•  ë•Œ $t_x, t_y, t_w, t_h$ë¥¼ ì˜ˆì¸¡í•œ í›„ ê·¸ë¦¼ì—ì„œì˜ $b_x, b_y, b_w, b_h$ë¡œ ë³€í˜•í•œ ë’¤ $L_2$ lossë¥¼ í†µí•´ í•™ìŠµì‹œì¼°ì§€ë§Œ, YOLOv3ì—ì„œëŠ” ground truthì˜ ì¢Œí‘œë¥¼ ê±°ê¾¸ë¡œ $\hat{t}_ {âˆ—}$ë¡œ ë³€í˜•ì‹œì¼œ ì˜ˆì¸¡í•œ $t_{âˆ—}$ì™€ ì§ì ‘ $L_1$ lossë¡œ í•™ìŠµì‹œí‚¨ë‹¤. ground truthì˜ $x, y$ì¢Œí‘œì˜ ê²½ìš° ì•„ë˜ì™€ ê°™ì´ ë³€í˜•ë˜ê³ ,

$$
\begin{aligned}&b_{âˆ—}= \sigma(\hat{t}_ {âˆ—}) + c_{âˆ—}\\      &\sigma(\hat{t}_ {âˆ—}) = b_{âˆ—} - c_{âˆ—}\\      &\hat{t}_ {âˆ—} = \sigma^{-1}(b_{âˆ—} - c_{âˆ—})\end{aligned}
$$

$w, h$ëŠ” ì•„ë˜ì™€ ê°™ì´ ë³€í˜•ëœë‹¤.

$$
\hat{t}_ {âˆ—} = \ln\left(\frac{b_{âˆ—}}{p_{âˆ—}}\right)
$$

ê²°ê³¼ì ìœ¼ë¡œ $x, y, w, h$ lossëŠ” ground truthì¸ $\hat{t}_ {âˆ—}$ prediction valueì¸ ${t}_ {âˆ—}$ì‚¬ì´ì˜ ì°¨ì´ $\hat{t}_ {âˆ—} - {t}_ {âˆ—}$ë¥¼ í†µí•œ Sum-Squared Error(SSE)ë¡œ êµ¬í•´ì§„ë‹¤.

## Model

<p align="center"><img src="/assets/images/yolov4/darknet53.png" height="35%" width="35%">    <img src="/assets/images/yolov4/model1.png" height="55%" width="55%"></p>

ëª¨ë¸ì˜ backboneì€ $3 \times 3$, $1 \times 1$ Residual connectionì„ ì‚¬ìš©í•˜ë©´ì„œ ìµœì¢…ì ìœ¼ë¡œ 53ê°œì˜ conv layerë¥¼ ì‚¬ìš©í•˜ëŠ” **Darknet-53** ì„ ì´ìš©í•œë‹¤. Darknet-53ì˜ Residual blockì•ˆì—ì„œë„ bottleneck êµ¬ì¡°ë¥¼ ì‚¬ìš©í•˜ë©°, inputì˜ channelì„ ì¤‘ê°„ì— ë°˜ìœ¼ë¡œ ì¤„ì˜€ë‹¤ê°€ ë‹¤ì‹œ ë³µêµ¬ì‹œí‚¤ëŠ”ë° ì´ë ‡ê²Œ í•˜ë¯€ë¡œì¨ ì—°ì‚°ëŸ‰ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤. ì´ë•Œ Residual blockì˜ $1 \times 1$ convëŠ” $s=1, p=0$ ì´ê³ , $3 \times 3$ convëŠ” $s=1, p=1$ì´ë‹¤.

YOLOv3 modelì˜ íŠ¹ì§•ì€ ë¬¼ì²´ì˜ scaleì„ ê³ ë ¤í•˜ì—¬ 3ê°€ì§€ í¬ê¸°ì˜ outputì´ ë‚˜ì˜¤ë„ë¡ FPNê³¼ ìœ ì‚¬í•˜ê²Œ ì„¤ê³„í•˜ì˜€ë‹¤ëŠ” ê²ƒì´ë‹¤. ì˜¤ë¥¸ìª½ ê·¸ë¦¼ê³¼ ê°™ì´ $416 \times 416$ì˜ í¬ê¸°ë¥¼ feature extractorë¡œ ë°›ì•˜ë‹¤ê³  í•˜ë©´, feature mapì´ í¬ê¸°ê°€ $52 \times 52$, $26 \times 26$, $13 \times 13$ì´ ë˜ëŠ” layerì—ì„œ ê°ê° feature mapì„ ì¶”ì¶œí•œë‹¤.

<p align="center"><img src="/assets/images/yolov4/model2.png"></p>


ê·¸ ë‹¤ìŒ ê°€ì¥ ë†’ì€ level, ì¦‰ í•´ìƒë„ê°€ ê°€ì¥ ë‚®ì€ feature mapë¶€í„° $1 \times 1$, $3 \times 3$ conv layerë¡œ êµ¬ì„±ëœ ì‘ì€ Fully Convolutional Network(FCN)ì— ì…ë ¥í•œë‹¤. ì´í›„ ì´ FCNì˜ output channelì´ 512ê°€ ë˜ëŠ” ì‹œì ì—ì„œ feature mapì„ ì¶”ì¶œí•œ ë’¤, $2\times$ë¡œ upsamplingì„ ì§„í–‰í•œë‹¤. ì´í›„ ë°”ë¡œ ì•„ë˜ levelì— ìˆëŠ” feature mapê³¼ concatenateë¥¼ í•´ì£¼ê³ , ì´ë ‡ê²Œ ë§Œë“¤ì–´ì§„ merged feature mapì„ ë‹¤ì‹œ FCNì— ì…ë ¥í•œë‹¤. ì´ ê³¼ì •ì„ ë‹¤ìŒ levelì—ë„ ë˜‘ê°™ì´ ì ìš©í•´ì£¼ê³  ì´ë ‡ê²Œ 3ê°œì˜ scaleì„ ê°€ì§„ feature mapì´ ë§Œë“¤ì–´ì§„ë‹¤. ê° scaleì— ë”°ë¼ ë‚˜ì˜¤ëŠ” ìµœì¢… feature mapì˜ í˜•íƒœëŠ” $N \times N \times \left[3 \cdot (4+1+80)\right]$ì´ë‹¤. ì—¬ê¸°ì„œ $3$ì€ grid cellë‹¹ predictí•˜ëŠ” anchor boxì˜ ìˆ˜ë¥¼, $4$ëŠ” bounding box offset $(x, y, w, h)$, $1$ì€ objectness prediction, $80$ì€ classì˜ ìˆ˜ ì´ë‹¤. ë”°ë¼ì„œ ìµœì¢…ì ìœ¼ë¡œ ì–»ëŠ” feature mapì€ $\left[52 \times 52 \times 255\right], \left[26 \times 26 \times 255\right], \left[13 \times 13 \times 255\right]$ì´ë‹¤.

ì´ëŸ¬í•œ ë°©ë²•ì„ í†µí•´ ë” ë†’ì€ levelì˜ feature mapìœ¼ë¡œë¶€í„° fine-grained ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆìœ¼ë©°, ë” ë‚®ì€ levelì˜ feature mapìœ¼ë¡œë¶€í„° ë” ìœ ìš©í•œ semantic ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.

## Loss Function

$$
Î»_ {coord} \sum_ {i=0}^{S^2} \sum_ {j=0}^B ğŸ™^{obj}_ {i j} \left[(t_ {x_ i} - \hat{t_ {x_ i}})^2 + (t_ {y_ i} - \hat{t_ {y_ i}})^2 \right] \\ +Î»_ {coord} \sum_ {i=0}^{S^2} \sum_ {j=0}^B ğŸ™^{obj}_ {i j} \left[(t_ {w_ i} - \hat{t_ {w_ i}})^2 + (t_ {h_ i} - \hat{t_ {h_ i}})^2 \right] \\ +\sum_{i=0}^{S^2} \sum_{j=0}^B ğŸ™^{obj}_{i j} \left[-(o_i\log(\hat{o_i}) + (1 - o_i)\log(1 - \hat{o_i}))\right] \\ +Mask_{ig} \cdot Î»_{noobj} \sum_{i=0}^{S^2} \sum_{j=0}^B ğŸ™^{noobj}_{i j} \left[-(o_i\log(\hat{o_i}) + (1 - o_i)\log(1 - \hat{o_i}))\right] \\ +\sum_{i=0}^{S^2} \sum_{j=0}^B ğŸ™^{obj}_ {i j} \sum_{c \in classes} \left[-(c_i\log(\hat{c_i}) + (1 - c_i)\log(1 - \hat{c_i}))\right]
$$

$S$ : number of cells

$B$ : number of anchors

$o$ : objectness

$c$ : class label

$Î»_ {coord}$ : coordinate loss balance constant

$Î»_{noobj}$ : no confidence loss balance constant

$ğŸ™^{obj}_ {i j}$ : 1 when there is object, 0 when there is no object

$ğŸ™^{noobj}_ {i j}$ : 1 when there is no object, 0 when there is object

$Mask_{ig}$ : tensor that masks only the anchor with iou $\le$ 0.5. Have a shape of $\left[S, S, B\right]$.

ê°ê°ì˜ boxëŠ” multi-label classificationì„ í•˜ê²Œ ë˜ëŠ”ë° ë…¼ë¬¸ì—ì„œëŠ” softmaxê°€ ì„±ëŠ¥ì´ ì¢‹ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì—, binary cross-entropy lossë¥¼ ì‚¬ìš©í–ˆë‹¤ê³  í•œë‹¤. í•˜ë‚˜ì˜ boxì•ˆì— ë³µìˆ˜ì˜ ê°ì²´ê°€ ì¡´ì¬í•˜ëŠ” ê²½ìš° softmaxëŠ” ì ì ˆí•˜ê²Œ ê°ì²´ë¥¼ ì•Œì•„ë‚´ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì—, box ì•ˆì— ê° classê°€ ì¡´ì¬í•˜ëŠ” ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” binary cross-entropyê°€ ë³´ë‹¤ ì ì ˆí•˜ë‹¤ê³  í•  ìˆ˜ ìˆë‹¤.

$o$ (objectness)ëŠ” anchorì™€ bboxì˜ iouê°€ ê°€ì¥ í° anchorì˜ ê°’ì´ 1, ê·¸ë ‡ì§€ ì•Šì€ ê²½ìš°ì˜ ê°’ì´ 0ì¸ $\left[N, N, 3, 1\right]$ì˜ tensorë¡œ ë§Œë“¤ì–´ì§„ë‹¤. $c$ (class label)ì€ one-encodingìœ¼ë¡œ $\left[N, N, 3, n \right]$ ($n$ : num_classes) ì˜ shapeë¥¼ ê°–ëŠ” tensorë¡œ ë§Œë“¤ì–´ì§„ë‹¤.

# YOLOv4

## Model

<p align="center"><img src="/assets/images/yolov4/CSPDarknet53.png" height="60%" width="60%"></p>

ì „ì²´ì ì¸ êµ¬ì¡°ëŠ” YOLOv3ê³¼ ìœ ì‚¬í•˜ì§€ë§Œ YOLOv4ëŠ” **CSPDarknet53+SPP**ë¥¼ ì‚¬ìš©í•œë‹¤. CSPDarknet53ì€ Darknet53ì— CSPNetì„ ì ìš©í•œ ê²ƒì´ë‹¤. CSPNetì€ ìœ„ ì‚¬ì§„ì˜ CSP Residual ë¶€ë¶„ê³¼ ê°™ì´ base layerì˜ feature mapì„ ë‘ ê°œë¡œ ë‚˜ëˆˆ ë’¤($X_0 \to X_0^{'}, X_0^{''}$) $X_0^{''}$ëŠ” Dense Layerì— í†µê³¼ ì‹œí‚¤ê³  $X_0^{'}$ëŠ” ê·¸ëŒ€ë¡œ ê°€ì ¸ì™€ì„œ ë§ˆì§€ë§‰ì— Dense Layerì˜ ì¶œë ¥ê°’ì¸ ($X_0^{''}, x_1, x_2, ...$)ì„ transition layerì— í†µê³¼ì‹œí‚¨ $X_T$ì™€ concatì‹œí‚¨ë‹¤. ì´í›„ concatëœ ê²°ê³¼ê°€ ë‹¤ìŒ transition layerë¥¼ í†µê³¼í•˜ë©´ì„œ $X_U$ê°€ ìƒì„±ëœë‹¤.

$$
\begin{aligned}X_k &= W_K^{ * }[X_0^{''}, X_1, ..., X_{k-1}]\\  X_T &= W_T^{ * }[X_0^{''}, X_1, ..., X_{k}]\\    X_U &= W_U^{ * }[X_0^{'}, X_T]\\      \end{aligned}  
$$

$$
\begin{aligned}W_k^{'} &= f(W_k, g_0^{''}, g_1, g_2, ..., g_{k-1})\\Â Â W_T^{'} &= f(W_T, g_0^{''}, g_1, g_2, ..., g_{k})\\Â Â W_U^{'} &= f(W_U, g_0^{'}, g_T)\\Â  Â  Â Â \end{aligned}
$$

ì´ë ‡ê²Œ í•˜ë¯€ë¡œì¨ CSPDenseNetì€ DenseNetì˜ feature reuse íŠ¹ì„±ì„ í™œìš©í•˜ë©´ì„œ, gradient flowë¥¼ truncate($X_0 \to X_0^{'}, X_0^{''}$)í•˜ì—¬ ê³¼ë„í•œ ì–‘ì˜ gradient information ë³µì‚¬ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆë‹¤.

## Box Loss

ì¼ë°˜ì ìœ¼ë¡œ IoU-based lossëŠ” ë‹¤ìŒê³¼ ê°™ì´ í‘œí˜„ëœë‹¤.

$$
L = 1 - IoU + \mathcal{R}(B, B^{gt})
$$

ì—¬ê¸°ì„œ $R(B, B^{gt})$ëŠ”  predicted box $B$ì™€ target box $B^{gt}$ì— ëŒ€í•œ penalty termì´ë‹¤.

$1 - IoU$ë¡œë§Œ Lossë¥¼ êµ¬í•  ê²½ìš° boxê°€ ê²¹ì¹˜ì§€ ì•ŠëŠ” caseì— ëŒ€í•´ì„œ ì–´ëŠ ì •ë„ì˜ ì˜¤ì°¨ë¡œ êµì§‘í•©ì´ ìƒê¸°ì§€ ì•Šì€ ê²ƒì¸ì§€ ì•Œ ìˆ˜ ì—†ì–´ì„œ gradient vanishing ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ penalty termì„ ì¶”ê°€í•œ ê²ƒì´ë‹¤.

### **Generalized-IoU(GIoU)**

Generalized-IoU(GIoU) ì˜ ê²½ìš° LossëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°ëœë‹¤.

$$
L_{GIoU} = 1 - IoU + \frac{|C - B âˆª B^{gt}|}{|C|}
$$

ì—¬ê¸°ì„œ $C$ëŠ” $B$ì™€ $B^{gt}$ë¥¼ ëª¨ë‘ í¬í•¨í•˜ëŠ” ìµœì†Œ í¬ê¸°ì˜ Boxë¥¼ ì˜ë¯¸í•œë‹¤. Generalized-IoUëŠ” ê²¹ì¹˜ì§€ ì•ŠëŠ” ë°•ìŠ¤ì— ëŒ€í•œ gradient vanishing ë¬¸ì œëŠ” ê°œì„ í–ˆì§€ë§Œ horizontalê³¼ verticalì— ëŒ€í•´ì„œ ì—ëŸ¬ê°€ í¬ë‹¤. ì´ëŠ” target boxì™€ ìˆ˜í‰, ìˆ˜ì§ì„ ì„ ì´ë£¨ëŠ” Anchor boxì— ëŒ€í•´ì„œëŠ” $\vert C - B âˆª B^{gt} \vert$ê°€ ë§¤ìš° ì‘ê±°ë‚˜ 0ì— ê°€ê¹Œì›Œì„œ IoUì™€ ë¹„ìŠ·í•˜ê²Œ ë™ì‘í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ë˜í•œ ê²¹ì¹˜ì§€ ì•ŠëŠ” boxì— ëŒ€í•´ì„œ ì¼ë‹¨ predicted boxì˜ í¬ê¸°ë¥¼ ë§¤ìš° í‚¤ìš°ê³  IoUë¥¼ ëŠ˜ë¦¬ëŠ” ë™ì‘ íŠ¹ì„± ë•Œë¬¸ì— ìˆ˜ë ´ ì†ë„ê°€ ëŠë¦¬ë‹¤.

### **Distance-IoU(DIoU)**

GIoUê°€ ë©´ì  ê¸°ë°˜ì˜ penalty termì„ ë¶€ì—¬í–ˆë‹¤ë©´, DIoUëŠ” ê±°ë¦¬ ê¸°ë°˜ì˜ penalty termì„ ë¶€ì—¬í•œë‹¤.
DIoUì˜ penalty termì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
\mathcal{R}_{DIoU} = \frac{\rho^2(b, b^{gt})}{c^2}
$$

$\rho^2$ëŠ” Euclideanê±°ë¦¬ì´ë©° $c$ëŠ” $B$ì™€ $B^{gt}$ë¥¼ í¬í•¨í•˜ëŠ” ê°€ì¥ ì‘ì€ Boxì˜ ëŒ€ê°ì„  ê±°ë¦¬ì´ë‹¤.

<p align="center"><img src="/assets/images/yolov4/diou.png" height="25%" width="25%"></p>


DIoU LossëŠ” ë‘ ê°œì˜ boxê°€ ì™„ë²½íˆ ì¼ì¹˜í•˜ë©´ 0, ë§¤ìš° ë©€ì–´ì§€ë©´ $L_{GIoU} = L_{DIoU} \to 2$ê°€ ëœë‹¤. ì´ëŠ” IoUê°€ 0ì´ ë˜ê³ , penalty termì´ 1ì— ê°€ê¹ê²Œ ë˜ê¸° ë•Œë¬¸ì´ë‹¤. Distance-IoUëŠ” ë‘ boxì˜ ì¤‘ì‹¬ ê±°ë¦¬ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ì¤„ì´ê¸° ë•Œë¬¸ì— GIoUì— ë¹„í•´ ìˆ˜ë ´ì´ ë¹ ë¥´ê³ , ê±°ë¦¬ê¸°ë°˜ì´ë¯€ë¡œ ìˆ˜í‰, ìˆ˜ì§ë°©í–¥ì—ì„œ ë˜í•œ ìˆ˜ë ´ì´ ë¹ ë¥´ë‹¤.

**DIoU-NMS**

DIoUë¥¼ NMS(Non-Maximum Suppression)ì—ë„ ì ìš©í•  ìˆ˜ ìˆë‹¤. ì¼ë°˜ì ì¸ NMSì˜ ê²½ìš° ì´ë¯¸ì§€ì—ì„œ ê°™ì€ classì¸ ë‘ ë¬¼ì²´ê°€ ê²¹ì³ìˆëŠ” Occlusion(ê°€ë¦¼)ì´ ë°œìƒí•œ ê²½ìš° ì˜¬ë°”ë¥¸ ë°•ìŠ¤ê°€ ì‚­ì œë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí•˜ëŠ”ë°, DIoUë¥¼ ì ‘ëª©í•  ê²½ìš° ë‘ ë°•ìŠ¤ì˜ ì¤‘ì‹¬ì  ê±°ë¦¬ë„ ê³ ë ¤í•˜ê¸° ë•Œë¬¸ì— target boxë¼ë¦¬ ê²¹ì³ì§„ ê²½ìš°ì—ë„ robustí•˜ê²Œ ë™ì‘í•  ìˆ˜ ìˆë‹¤.

$$
s_i =\begin{cases}s_ i, & IoU - \mathcal{R}_ {DIoU}(\mathcal{M}, B_i) < \epsilon\\0, & IoU - \mathcal{R}_{DIoU}(\mathcal{M}, B_i) \ge \epsilon\end{cases}
$$

ê°€ì¥ ë†’ì€ Confidence scoreë¥¼ ê°–ëŠ” $\mathcal{M}$ì— ëŒ€í•´ IoUì™€ DIoUì˜ distance penaltyë¥¼ ë™ì‹œì— ê³ ë ¤í•˜ì—¬ IoUê°€ ë§¤ìš° í¬ë”ë¼ë„ ì¤‘ì‹¬ì  ì‚¬ì´ì˜ ê±°ë¦¬ê°€ ë©€ë©´ ë‹¤ë¥¸ ê°ì²´ë¥¼ íƒì§€í•œ ê²ƒì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ ìœ„ì™€ ê°™ì´ ì¼ì • ì„ê³„ì¹˜ $\epsilon$ ë³´ë‹¤ ì‘ìœ¼ë©´ ì—†ì• ì§€ ì•Šê³  ë³´ì¡´í•œë‹¤.

### **Complete-IoU(CIoU)**

DIoU, CIoUë¥¼ ì œì•ˆí•œ ë…¼ë¬¸ì—ì„œ ë§í•˜ëŠ” ì„±ê³µì ì¸ Bounding Box Regressionì„ ìœ„í•œ 3ê°€ì§€ ì¡°ê±´ì€ overlap area, central point
distance, aspect ratioì´ë‹¤. ì´ ì¤‘ overlap area, central pointëŠ” DIoUì—ì„œ ì´ë¯¸ ê³ ë ¤í–ˆê³  ì—¬ê¸°ì— aspect ratioë¥¼ ê³ ë ¤í•œ penalty termì„ ì¶”ê°€í•œ ê²ƒì´ CIoUì´ë‹¤. CIoU penalty termëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ì˜ëœë‹¤.

$$
\mathcal{R}_{CIoU} = \frac{\rho^2(b, b^{gt})}{c^2} + \alpha v \\ v = \frac{4}{Ï€^2}(\arctan{\frac{w^{gt}}{h^{gt}}} - \arctan{\frac{w}{h}})^2 \\ \alpha = \frac{v}{(1 - IoU) + v}
$$

$v$ì˜ ê²½ìš° bboxëŠ” ì§ì‚¬ê°í˜•ì´ê³  $\arctan{\frac{w}{h}} = \theta$ì´ë¯€ë¡œ $\theta$ì˜ ì°¨ì´ë¥¼ í†µí•´ aspect ratioë¥¼ êµ¬í•˜ê²Œ ëœë‹¤. ì´ë•Œ $v$ì— $\frac{2}{Ï€}$ê°€ ê³±í•´ì§€ëŠ” ì´ìœ ëŠ” $\arctan$ í•¨ìˆ˜ì˜ ìµœëŒ€ì¹˜ê°€ $\frac{2}{Ï€}$ ì´ë¯€ë¡œ scaleì„ ì¡°ì •í•´ì£¼ê¸° ìœ„í•´ì„œì´ë‹¤.

$\alpha$ëŠ” trade-off íŒŒë¼ë¯¸í„°ë¡œ IoUê°€ í° boxì— ëŒ€í•´ ë” í° penaltyë¥¼ ì£¼ê²Œ ëœë‹¤.

CIoUì— ëŒ€í•´ ìµœì í™”ë¥¼ ìˆ˜í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ ê¸°ìš¸ê¸°ë¥¼ ì–»ê²Œ ëœë‹¤. ì´ë•Œ, $w, h$ëŠ” ëª¨ë‘ 0ê³¼ 1ì‚¬ì´ë¡œ ê°’ì´ ì‘ì•„ gradient explosionì„ ìœ ë°œí•  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ ì‹¤ì œ êµ¬í˜„ ì‹œì—ëŠ” $\frac{1}{w^2 + h^2} = 1$ë¡œ ì„¤ì •í•œë‹¤.

$$
\frac{\partial v}{\partial w} = \frac{8}{Ï€^2}(\arctan{\frac{w^{gt}}{h^{gt}}} - \arctan{\frac{w}{h}}) \times \frac{h}{w^2 + h^2} \\ \frac{\partial v}{\partial h} = -\frac{8}{Ï€^2}(\arctan{\frac{w^{gt}}{h^{gt}}} - \arctan{\frac{w}{h}}) \times \frac{w}{w^2 + h^2}
$$

## Cosine Annealing

$$
\eta_t = \eta_{\min} + \frac{1}{2}(\eta_{\max} - \eta_{\min})\left(1 + \cos{\left(\frac{T_{cur}}{T_{\max}}\pi\right)} \right), \ T_{cur} \neq (2k+1)T_{\max}
$$

$\eta_{\min}$ : min learning rate

$\eta_{\max}$ : max learning rate

$T_{\max}$ : period

# YOLOv4 Implementation
ì „ì²´ì ì¸ í‹€ì€ Aladdin Perssonì˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¸ê³ í•˜ì˜€ê³ , YOLOv4 modelì€ ë…¼ë¬¸ê³¼ YOLOv4 diagramì— ê¸°ë°˜í•˜ì—¬ ì§ì ‘ êµ¬í˜„í•´ë³´ì•˜ë‹¤. 

### Backbone 

```py
class DarknetConv2D(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride, act="mish", bn_act=True):
        super().__init__()

        padding = (kernel_size - 1) // 2

        self.conv = nn.Conv2d(
            in_channels=in_channels, out_channels=out_channels,
            kernel_size=kernel_size, stride=stride, padding=padding,
            bias=not bn_act
        )

        self.bn = nn.BatchNorm2d(out_channels)
        self.mish = nn.Mish()
        self.leaky = nn.LeakyReLU(0.1, inplace=True)
        self.use_bn_act = bn_act
        self.act = act

    def forward(self, x):
        if self.use_bn_act:
            if self.act == "mish":
                return self.mish(self.bn(self.conv(x)))
            elif self.act == "leaky":
                return self.leaky(self.bn(self.conv(x)))
        else:
            return self.conv(x)
```

```py
class CSPResBlock(nn.Module):
    def __init__(self, in_channels, is_first=False, num_repeats=1):
        super().__init__()

        self.route_1 = DarknetConv2D(in_channels, in_channels//2, 1, 1, 'mish')
        self.route_2 = DarknetConv2D(in_channels, in_channels//2, 1, 1, 'mish')
        self.res1x1 = DarknetConv2D(in_channels//2, in_channels//2, 1, 1, 'mish')
        self.concat1x1 = DarknetConv2D(in_channels, in_channels, 1, 1, 'mish')
        self.num_repeats = num_repeats

        self.DenseBlock = nn.ModuleList()
        for i in range(num_repeats):
            DenseLayer = nn.ModuleList()
            DenseLayer.append(DarknetConv2D(in_channels//2, in_channels//2, 1, 1, 'mish'))
            DenseLayer.append(DarknetConv2D(in_channels//2, in_channels//2, 3, 1, 'mish'))
            self.DenseBlock.append(DenseLayer)

        if is_first:
            self.route_1 = DarknetConv2D(in_channels, in_channels, 1, 1, 'mish')
            self.route_2 = DarknetConv2D(in_channels, in_channels, 1, 1, 'mish')
            self.res1x1 = DarknetConv2D(in_channels, in_channels, 1, 1, 'mish')
            self.concat1x1 = DarknetConv2D(in_channels*2, in_channels, 1, 1, 'mish')

            self.DenseBlock = nn.ModuleList()
            for i in range(num_repeats):
                DenseLayer = nn.ModuleList()
                DenseLayer.append(DarknetConv2D(in_channels, in_channels//2, 1, 1, 'mish'))
                DenseLayer.append(DarknetConv2D(in_channels//2, in_channels, 3, 1, 'mish'))
                self.DenseBlock.append(DenseLayer)

    def forward(self, x):
        route = self.route_1(x)
        x = self.route_2(x)

        for module in self.DenseBlock:
            h = x
            for res in module:
                h = res(h)
            x = h + x

        x = self.res1x1(x)
        x = torch.cat([x, route], dim=1)
        x = self.concat1x1(x)

        return x
```

```py
class CSPDarknet53(nn.Module):
    def __init__(self, in_channels):
        super().__init__()

        self.in_channels = in_channels

        self.layers = nn.ModuleList([
            DarknetConv2D(in_channels, 32, 3, 1, 'mish'),
            DarknetConv2D(32, 64, 3, 2, 'mish'),
            CSPResBlock(in_channels=64, is_first=True, num_repeats=1),
            DarknetConv2D(64, 128, 3, 2, 'mish'),
            CSPResBlock(in_channels=128, num_repeats=2),
            DarknetConv2D(128, 256, 3, 2, 'mish'),
            CSPResBlock(in_channels=256, num_repeats=8), # P3
            DarknetConv2D(256, 512, 3, 2, 'mish'),
            CSPResBlock(in_channels=512, num_repeats=8), # P4
            DarknetConv2D(512, 1024, 3, 2, 'mish'),
            CSPResBlock(in_channels=1024, num_repeats=4) # P5
        ])

    def forward(self, x):
        route = []

        for layer in self.layers:
            x = layer(x)

            if (isinstance(layer, CSPResBlock) and layer.num_repeats == 8) or (isinstance(layer, CSPResBlock) and layer.num_repeats == 4):
                route.append(x)

        P5, P4, P3 = route[2], route[1], route[0]

        return P5, P4, P3
```

### Neck 

```py
class SPP(nn.Module):
    def __init__(self):
        super().__init__()

        self.maxpool5 = nn.MaxPool2d(kernel_size=5, stride=1, padding=2)
        self.maxpool9 = nn.MaxPool2d(kernel_size=9, stride=1, padding=4)
        self.maxpool13 = nn.MaxPool2d(kernel_size=13, stride=1, padding=6)

    def forward(self, x):
        x = torch.cat([self.maxpool13(x),
                       self.maxpool9(x),
                       self.maxpool5(x),
                       x], dim=1)

        return x
```

```py
class Conv5(nn.Module):
    def __init__(self, in_channels):
        super().__init__()

        self.in_channels = in_channels
        self.conv1x1 = DarknetConv2D(in_channels, in_channels//2, 1, 1, "leaky")
        self.conv3x3 = DarknetConv2D(in_channels//2, in_channels, 3, 1, "leaky")

    def forward(self, x):
        x = self.conv1x1(x)
        x = self.conv3x3(x)
        x = self.conv1x1(x)
        x = self.conv3x3(x)
        x = self.conv1x1(x)

        return x



class Conv3(nn.Module):
    def __init__(self):
        super().__init__()

        self.layers = nn.ModuleList([
            DarknetConv2D(2048, 512, 1, 1, "leaky"),
            DarknetConv2D(512, 1024, 3, 1, "leaky"),
            DarknetConv2D(1024, 512, 1, 1, "leaky")
        ])

    def forward(self, x):
        for layer in self.layers:
            x = layer(x)

        return x
```

```py
class PANet(nn.Module):
    def __init__(self):
        super().__init__()

        self.UpConv_P4 = DarknetConv2D(512, 256, 1, 1, "leaky")
        self.UpConv_P3 = DarknetConv2D(256, 128, 1, 1, "leaky")

        self.layers = nn.ModuleList([
            DarknetConv2D(1024, 512, 1, 1, "leaky"),
            DarknetConv2D(512, 1024, 3, 1, "leaky"),
            DarknetConv2D(1024, 512, 1, 1, "leaky"),
            SPP(),
            Conv3(), # N5
            DarknetConv2D(512, 256, 1, 1, "leaky"),
            nn.Upsample(scale_factor=2, mode='nearest'),
            Conv5(in_channels=512), # N4
            DarknetConv2D(256, 128, 1, 1, "leaky"),
            nn.Upsample(scale_factor=2, mode='nearest'),
            Conv5(in_channels=256) # N3
        ])

    def forward(self, P5, P4, P3):
        P4 = self.UpConv_P4(P4)
        P3 = self.UpConv_P3(P3)

        P = [P3, P4]
        N = []

        x = P5
        for layer in self.layers:
            x = layer(x)

            if isinstance(layer, nn.Upsample):
                x = torch.cat([P[-1], x], dim=1)
                P.pop()

            if isinstance(layer, Conv3):
                N.append(x)

            if isinstance(layer, Conv5):
                N.append(x)

        N5, N4, N3 = N[0], N[1], N[2]

        return N3, N4, N5
```

### Head

```py
class ScalePrediction(nn.Module):
    def __init__(self, in_channels, num_classes):
        super().__init__()

        self.conv = DarknetConv2D(in_channels, in_channels*2, 3, 1, "leaky")
        self.ScalePred = DarknetConv2D(in_channels*2, 3*(num_classes+5), 1, 1, bn_act=False)
        self.num_classes = num_classes

    def forward(self, x):
        return(
            self.ScalePred(self.conv(x))
            # x = [batch_num, 3*(num_classes + 5), N, N
            .reshape(x.shape[0], 3, self.num_classes + 5, x.shape[2], x.shape[3])
            .permute(0, 1, 3, 4, 2)
            # output = [B x 3 x N x N x 5+num_classes]
        )
```

```py
class YOLOv4(nn.Module):
    def __init__(self, in_channels=3, num_classes=20):
        super().__init__()

        self.CSPDarknet53 = CSPDarknet53(in_channels)
        self.PANet = PANet()

        self.layers = nn.ModuleList([
            ScalePrediction(in_channels=128, num_classes=num_classes), # sbbox 52x52
            DarknetConv2D(128, 256, 3, 2, "leaky"),
            Conv5(in_channels=512),
            ScalePrediction(in_channels=256, num_classes=num_classes), # mbbox 26x26
            DarknetConv2D(256, 512, 3, 2, "leaky"),
            Conv5(in_channels=1024),
            ScalePrediction(in_channels=512, num_classes=num_classes)  # lbbox 13x13
        ])

    def forward(self, x):
        P5, P4, P3 = self.CSPDarknet53(x)
        N3, N4, N5 = self.PANet(P5, P4, P3)
        N = [N5, N4]

        outputs = []

        x = N3
        for layer in self.layers:

            if isinstance(layer, ScalePrediction):
                outputs.append(layer(x))
                continue # Since this is the output of each scale, it must skip x = ScalePrediction(x).

            x = layer(x)

            if isinstance(layer, DarknetConv2D):
                x = torch.cat([x, N[-1]], dim=1)
                N.pop()

        outputs[0], outputs[1], outputs[2] = outputs[2], outputs[1], outputs[0]
        
        # lbbox 13x13 -> torch.Size([1, 13, 13, 255])
        # mbbox 26x26 -> torch.Size([1, 26, 26, 255])
        # sbbox 52x52 -> torch.Size([1, 52, 52, 255])

        return outputs
```


