---
title:  "Raum"
excerpt: "Brain Tumor Segmentation using U-Net Transformer"

categories:
  - Computer Vision
tags:
  - Project
  - Segmentation
last_modified_at: 2024-12-28T08:06:00-05:00
---


# UNETR: Transformers for 3D Medical Image Segmentation

## Vision Transformer 

<p align="center"><img src="https://github.com/user-attachments/assets/18f39354-27e4-4cce-8df0-6846851be9f5"></p>

NLP에서의 Transformer가 1D sequence of input embeddings을 입력 받기 때문에 Vision 분야에서도 유사하게 2D, 3D입력을 1D로 변환해줄 필요가 있다. UNETR에서 제안하는 3D을 기준으로 설명하면 resolution $(H, W, D)$ Channel $C$의 3D input volume $\mathbf{x} \in \mathbb{R}^{H \times W \times D \times C}$ 을 Flatten 시켜서 $\mathbf{x}_v \in \mathbb{R}^{N \times (P^3 \cdot C)}$ 으로 만든다. 여기서 $(P, P, P)$는 image patch의 resolution이고, $N = (H \times W \times D) / P^3$ 은 Patch의 수, length of the sequence이다. 

이렇게 Flatten한 Patch를 학습 가능한 Linear Projection($E$) ( $E \in \mathbb{R}^{(P^3 \cdot C) \times K}$ ) 을 통해 K dimensional embedding space으로 만든다. 이후 NLP 처럼 이미지의 위치 정보를 보존하기 위해 학습 가능한 1D positional embedding ($E_{pos} \in \mathbb{R}^{N \times K}$) 을 embedding결과에 더해준다. 

$$z_0 = [\mathbf{x}_v^1E; \mathbf{x}_v^2E; ...; \mathbf{x}_v^NE] + E_{pos}$$

여기선 semantic segmentation이 목적이기 때문에 [CLS] Token은 사용되지 않는다. 

embedding이 끝난 후 본격적으로 Transformer 네트워크를 통과한다. 여기서 부턴 NLP에서의 과정과 매우 유사하다. 

$$z_i^{\prime} = MSA(Norm(z_{i-1})) + z_{i-1}, i=1...L$$

$$z_i = MLP(Norm(z_i^{\prime})) + z_i^{\prime}, i=1...L$$

**multilayer perceptron (MLP)** 은 **GELU** activation를 사용하는 2개의 linear layers로 이루어져 있고, $L$은 transformer layers를 반복하는 수이다. 

**multi-head self-attention (MSA)** 은 $n$ parallel self-attention(SA) heads로 이루여져 있으며 다음과 같이 계산한다. 




## Architecture

<p align="center"><img src="https://github.com/user-attachments/assets/0cc46698-0fff-4973-9eb1-0ae773f59eca"></p>

transformer를 활용한 다른 3D medical image segmentation 연구에서는 CNN을 feature extraction에 사용하고 Encoder와 Decoder를 잇는 bottleneck에 transformer를 두는 방식을 제안하였다. 하지만 본 논문에서는 transformer를 Encoder에 사용하고, 이를 바로 Decoder와 skip connections으로 연결하는 방법을 제안한다.   
모델에서 Transformer를 Encoder할 때만 사용하고 Decoder할 때는 CNN-based를 사용하는 이유는 Transformer가 global information는 매우 잘 잡아내지만, localized information에 대해서는 부적합하기 때문이다. 



Related Work부터...

# Project: Brain Tumor Segmentation using UNETR

프로젝트 진행중 ... 
